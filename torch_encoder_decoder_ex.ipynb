{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "path = osp.join(osp.dirname(osp.realpath(\".\")), '..', 'data', 'Planetoid')\n",
    "dataset = Planetoid(path, name='Cora', transform=transform)\n",
    "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
    "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
    "# each element representing the corresponding split.\n",
    "train_data, val_data, test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[4488], edge_label_index=[2, 4488])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge_labels(graph):\n",
    "    transform = T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False)\n",
    "    return transform(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_graphs = [add_edge_labels(graph) for graph in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[101, 2], edge_index=[2, 1308], y=[101, 101], pos=[101, 2], edge_label=[654], edge_label_index=[2, 654]),\n",
       " Data(x=[101, 2], edge_index=[2, 1308], y=[101, 101], pos=[101, 2], edge_label=[76], edge_label_index=[2, 76]),\n",
       " Data(x=[101, 2], edge_index=[2, 1384], y=[101, 101], pos=[101, 2], edge_label=[152], edge_label_index=[2, 152]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(data_list[0].num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "\n",
    "        # We perform a new round of negative sampling for every training epoch:\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=batch.edge_index, num_nodes=batch.num_nodes,\n",
    "            num_neg_samples=batch.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "        # Concat positive and negative edge indices.\n",
    "        edge_label_index = torch.cat(\n",
    "            [batch.edge_label_index, neg_edge_index],\n",
    "            dim=-1,\n",
    "        )\n",
    "        # Label for positive edges: 1, for negative edges: 0.\n",
    "        edge_label = torch.cat([\n",
    "            batch.edge_label,\n",
    "            batch.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "        ], dim=0)\n",
    "\n",
    "        # Note: The model is trained in a supervised manner using the given\n",
    "        # `edge_label_index` and `edge_label` targets.\n",
    "        out = model.decode(z, edge_label_index).view(-1)\n",
    "        loss = criterion(out, edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    all_out = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in loader:\n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "        out = model.decode(z, batch.edge_label_index).view(-1).sigmoid()\n",
    "        all_out.append(out.cpu().numpy())\n",
    "        all_labels.append(batch.edge_label.cpu().numpy())\n",
    "\n",
    "    all_out = np.concatenate(all_out)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return roc_auc_score(all_labels, all_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 107.0461, Val: 0.8452, Test: 0.8478\n",
      "Epoch: 002, Loss: 1.4814, Val: 0.8528, Test: 0.8560\n",
      "Epoch: 003, Loss: 0.7313, Val: 0.8598, Test: 0.8625\n",
      "Epoch: 004, Loss: 0.5962, Val: 0.8658, Test: 0.8684\n",
      "Epoch: 005, Loss: 0.5604, Val: 0.8709, Test: 0.8731\n",
      "Epoch: 006, Loss: 0.5507, Val: 0.8736, Test: 0.8755\n",
      "Epoch: 007, Loss: 0.5467, Val: 0.8755, Test: 0.8775\n",
      "Epoch: 008, Loss: 0.5457, Val: 0.8770, Test: 0.8786\n",
      "Epoch: 009, Loss: 0.5441, Val: 0.8774, Test: 0.8790\n",
      "Epoch: 010, Loss: 0.5432, Val: 0.8788, Test: 0.8805\n",
      "Epoch: 011, Loss: 0.5434, Val: 0.8798, Test: 0.8815\n",
      "Epoch: 012, Loss: 0.5422, Val: 0.8813, Test: 0.8832\n",
      "Epoch: 013, Loss: 0.5423, Val: 0.8820, Test: 0.8839\n",
      "Epoch: 014, Loss: 0.5402, Val: 0.8832, Test: 0.8852\n",
      "Epoch: 015, Loss: 0.5402, Val: 0.8849, Test: 0.8870\n",
      "Epoch: 016, Loss: 0.5389, Val: 0.8867, Test: 0.8889\n",
      "Epoch: 017, Loss: 0.5376, Val: 0.8884, Test: 0.8907\n",
      "Epoch: 018, Loss: 0.5377, Val: 0.8910, Test: 0.8934\n",
      "Epoch: 019, Loss: 0.5363, Val: 0.8930, Test: 0.8955\n",
      "Epoch: 020, Loss: 0.5349, Val: 0.8961, Test: 0.8987\n",
      "Epoch: 021, Loss: 0.5328, Val: 0.8988, Test: 0.9014\n",
      "Epoch: 022, Loss: 0.5311, Val: 0.9018, Test: 0.9045\n",
      "Epoch: 023, Loss: 0.5283, Val: 0.9051, Test: 0.9077\n",
      "Epoch: 024, Loss: 0.5261, Val: 0.9092, Test: 0.9118\n",
      "Epoch: 025, Loss: 0.5233, Val: 0.9127, Test: 0.9154\n",
      "Epoch: 026, Loss: 0.5206, Val: 0.9160, Test: 0.9188\n",
      "Epoch: 027, Loss: 0.5185, Val: 0.9190, Test: 0.9217\n",
      "Epoch: 028, Loss: 0.5157, Val: 0.9222, Test: 0.9250\n",
      "Epoch: 029, Loss: 0.5132, Val: 0.9238, Test: 0.9264\n",
      "Epoch: 030, Loss: 0.5108, Val: 0.9264, Test: 0.9291\n",
      "Epoch: 031, Loss: 0.5092, Val: 0.9278, Test: 0.9305\n",
      "Epoch: 032, Loss: 0.5084, Val: 0.9285, Test: 0.9311\n",
      "Epoch: 033, Loss: 0.5077, Val: 0.9300, Test: 0.9326\n",
      "Epoch: 034, Loss: 0.5072, Val: 0.9293, Test: 0.9319\n",
      "Epoch: 035, Loss: 0.5062, Val: 0.9311, Test: 0.9335\n",
      "Epoch: 036, Loss: 0.5058, Val: 0.9312, Test: 0.9336\n",
      "Epoch: 037, Loss: 0.5045, Val: 0.9319, Test: 0.9343\n",
      "Epoch: 038, Loss: 0.5051, Val: 0.9323, Test: 0.9346\n",
      "Epoch: 039, Loss: 0.5043, Val: 0.9319, Test: 0.9343\n",
      "Epoch: 040, Loss: 0.5041, Val: 0.9322, Test: 0.9345\n",
      "Epoch: 041, Loss: 0.5039, Val: 0.9324, Test: 0.9348\n",
      "Epoch: 042, Loss: 0.5032, Val: 0.9329, Test: 0.9351\n",
      "Epoch: 043, Loss: 0.5029, Val: 0.9329, Test: 0.9351\n",
      "Epoch: 044, Loss: 0.5030, Val: 0.9333, Test: 0.9356\n",
      "Epoch: 045, Loss: 0.5036, Val: 0.9327, Test: 0.9350\n",
      "Epoch: 046, Loss: 0.5031, Val: 0.9332, Test: 0.9354\n",
      "Epoch: 047, Loss: 0.5027, Val: 0.9332, Test: 0.9355\n",
      "Epoch: 048, Loss: 0.5016, Val: 0.9338, Test: 0.9360\n",
      "Epoch: 049, Loss: 0.5032, Val: 0.9332, Test: 0.9354\n",
      "Epoch: 050, Loss: 0.5035, Val: 0.9337, Test: 0.9358\n",
      "Epoch: 051, Loss: 0.5033, Val: 0.9340, Test: 0.9363\n",
      "Epoch: 052, Loss: 0.5020, Val: 0.9336, Test: 0.9358\n",
      "Epoch: 053, Loss: 0.5026, Val: 0.9341, Test: 0.9363\n",
      "Epoch: 054, Loss: 0.5029, Val: 0.9344, Test: 0.9366\n",
      "Epoch: 055, Loss: 0.5022, Val: 0.9343, Test: 0.9365\n",
      "Epoch: 056, Loss: 0.5020, Val: 0.9342, Test: 0.9364\n",
      "Epoch: 057, Loss: 0.5009, Val: 0.9344, Test: 0.9367\n",
      "Epoch: 058, Loss: 0.5009, Val: 0.9348, Test: 0.9369\n",
      "Epoch: 059, Loss: 0.5008, Val: 0.9351, Test: 0.9372\n",
      "Epoch: 060, Loss: 0.5004, Val: 0.9348, Test: 0.9371\n",
      "Epoch: 061, Loss: 0.5018, Val: 0.9350, Test: 0.9373\n",
      "Epoch: 062, Loss: 0.5009, Val: 0.9355, Test: 0.9377\n",
      "Epoch: 063, Loss: 0.5003, Val: 0.9355, Test: 0.9376\n",
      "Epoch: 064, Loss: 0.4997, Val: 0.9352, Test: 0.9374\n",
      "Epoch: 065, Loss: 0.5005, Val: 0.9358, Test: 0.9381\n",
      "Epoch: 066, Loss: 0.4994, Val: 0.9351, Test: 0.9374\n",
      "Epoch: 067, Loss: 0.5001, Val: 0.9361, Test: 0.9383\n",
      "Epoch: 068, Loss: 0.5000, Val: 0.9359, Test: 0.9378\n",
      "Epoch: 069, Loss: 0.5000, Val: 0.9362, Test: 0.9383\n",
      "Epoch: 070, Loss: 0.5000, Val: 0.9368, Test: 0.9387\n",
      "Epoch: 071, Loss: 0.4999, Val: 0.9342, Test: 0.9362\n",
      "Epoch: 072, Loss: 0.5007, Val: 0.9365, Test: 0.9387\n",
      "Epoch: 073, Loss: 0.4992, Val: 0.9355, Test: 0.9375\n",
      "Epoch: 074, Loss: 0.4982, Val: 0.9374, Test: 0.9394\n",
      "Epoch: 075, Loss: 0.5002, Val: 0.9363, Test: 0.9383\n",
      "Epoch: 076, Loss: 0.5001, Val: 0.9373, Test: 0.9394\n",
      "Epoch: 077, Loss: 0.4994, Val: 0.9373, Test: 0.9394\n",
      "Epoch: 078, Loss: 0.4994, Val: 0.9352, Test: 0.9372\n",
      "Epoch: 079, Loss: 0.5013, Val: 0.9375, Test: 0.9395\n",
      "Epoch: 080, Loss: 0.4994, Val: 0.9379, Test: 0.9400\n",
      "Epoch: 081, Loss: 0.4976, Val: 0.9375, Test: 0.9395\n",
      "Epoch: 082, Loss: 0.4982, Val: 0.9373, Test: 0.9394\n",
      "Epoch: 083, Loss: 0.4984, Val: 0.9380, Test: 0.9399\n",
      "Epoch: 084, Loss: 0.4957, Val: 0.9380, Test: 0.9401\n",
      "Epoch: 085, Loss: 0.4975, Val: 0.9381, Test: 0.9402\n",
      "Epoch: 086, Loss: 0.4997, Val: 0.9380, Test: 0.9400\n",
      "Epoch: 087, Loss: 0.4983, Val: 0.9380, Test: 0.9400\n",
      "Epoch: 088, Loss: 0.4981, Val: 0.9385, Test: 0.9406\n",
      "Epoch: 089, Loss: 0.4963, Val: 0.9395, Test: 0.9413\n",
      "Epoch: 090, Loss: 0.4975, Val: 0.9395, Test: 0.9414\n",
      "Epoch: 091, Loss: 0.4970, Val: 0.9345, Test: 0.9365\n",
      "Epoch: 092, Loss: 0.4971, Val: 0.9376, Test: 0.9396\n",
      "Epoch: 093, Loss: 0.4968, Val: 0.9389, Test: 0.9409\n",
      "Epoch: 094, Loss: 0.4963, Val: 0.9393, Test: 0.9412\n",
      "Epoch: 095, Loss: 0.4960, Val: 0.9383, Test: 0.9403\n",
      "Epoch: 096, Loss: 0.4972, Val: 0.9390, Test: 0.9409\n",
      "Epoch: 097, Loss: 0.4965, Val: 0.9369, Test: 0.9388\n",
      "Epoch: 098, Loss: 0.5013, Val: 0.9392, Test: 0.9411\n",
      "Epoch: 099, Loss: 0.4981, Val: 0.9403, Test: 0.9421\n",
      "Epoch: 100, Loss: 0.4974, Val: 0.9391, Test: 0.9413\n",
      "Final Test: 0.9421\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Loop\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(train_loader)\n",
    "    val_auc = test(val_loader)\n",
    "    test_auc = test(test_loader)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "z = model.encode(train_size[0].x, train_size[0].edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0975,  0.0965,  0.1179,  ..., -0.2019, -0.0823,  0.2832],\n",
       "        [ 0.1081, -0.1024,  0.2862,  ...,  0.0125, -0.0514, -0.0633],\n",
       "        [ 0.0154, -0.0206,  0.2033,  ..., -0.2354, -0.1704,  0.2083],\n",
       "        ...,\n",
       "        [ 0.2875, -0.0498, -0.3933,  ..., -0.0443,  0.0819, -0.1261],\n",
       "        [ 0.0784, -0.0241,  0.2030,  ...,  0.1055,  0.0498, -0.2083],\n",
       "        [ 0.3449, -0.1079, -0.2666,  ..., -0.3180,  0.0281, -0.0787]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "fei = final_edge_index.tolist()\n",
    "edges_pred = {k:[] for k in range(101)}\n",
    "edges_pred_inv = {k:[] for k in range(101)}\n",
    "for i in range(len(fei[0])):\n",
    "    edges_pred[fei[0][i]].append(fei[1][i])\n",
    "    edges_pred_inv[fei[1][i]].append(fei[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts0 = train_size[0].edge_index.tolist()\n",
    "edges = {k:[] for k in range(101)}\n",
    "edges_inv = {k:[] for k in range(101)}\n",
    "for i in range(len(ts0[0])):\n",
    "    edges[ts0[0][i]].append(ts0[1][i])\n",
    "    edges_inv[ts0[1][i]].append(ts0[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 68, 22, 88]\n",
      "[72, 68, 22, 88]\n"
     ]
    }
   ],
   "source": [
    "print(edges[0])\n",
    "print(edges_inv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "[0, 1, 2, 4, 5, 7, 12, 16, 21, 22, 24, 26, 30, 33, 35, 36, 38, 39, 42, 45, 47, 48, 50, 54, 57, 58, 59, 67, 68, 72, 76, 79, 81, 84, 87, 88, 89, 94]\n"
     ]
    }
   ],
   "source": [
    "print(len(edges_pred[0]))\n",
    "print(edges_pred_inv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now a chatgpt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DotProductDecoder, self).__init__()\n",
    "\n",
    "    def forward(self, z):\n",
    "        adj_pred = torch.sigmoid(torch.matmul(z, z.t()))\n",
    "        return adj_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphAutoencoder, self).__init__()\n",
    "        self.encoder = GNNEncoder(input_dim, hidden_dim, output_dim)\n",
    "        self.decoder = DotProductDecoder()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        z = self.encoder(x, edge_index)\n",
    "        adj_pred = self.decoder(z)\n",
    "        return adj_pred, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from random import randint\n",
    "from sys import float_info\n",
    "\n",
    "instances = {}\n",
    "for k in range(0, 1000):\n",
    "    nodes = {}\n",
    "    for i in range(0, 50):\n",
    "        lat_i = randint(0, 100)\n",
    "        lon_i = randint(0, 100)\n",
    "        node_i = (lat_i, lon_i)\n",
    "        lat_j = randint(0, 100)\n",
    "        lon_j = randint(0, 100)\n",
    "        node_j = (lat_j, lon_j)\n",
    "        nodes[i + 1] = node_i\n",
    "        nodes[i + 51] = node_j\n",
    "\n",
    "    dist = {}\n",
    "    pairs = {}\n",
    "    for i in range(1, 101):\n",
    "        for j in range(1, 101):\n",
    "            if i != j:\n",
    "                dist[i,j] = sqrt( (nodes[i][0] - nodes[j][0])**2 + (nodes[i][1] - nodes[j][1])**2 )\n",
    "            else:\n",
    "                dist[i,j] = float_info.max\n",
    "    for i in range(1, 101):\n",
    "        for j in range(1, 101):\n",
    "            if i not in pairs:\n",
    "                pairs[i] = j\n",
    "            if i != j:\n",
    "                if dist[i,j] < dist[i,pairs[i]]:\n",
    "                    pairs[i] = j\n",
    "\n",
    "    nodes[0] = (0,0)\n",
    "    for i in range(1,101):\n",
    "        dist[0,i] = sqrt( (nodes[0][0] - nodes[i][0])**2 + (nodes[0][1] - nodes[i][1])**2 )\n",
    "        dist[i,0] = dist[0,i]\n",
    "    y = [[0 for _ in range(101)] for _ in range(101)]\n",
    "    for i in range(101):\n",
    "        if i > 0:\n",
    "            y[i][pairs[i]] = 1\n",
    "                \n",
    "    instances[k] = {\"nodes\": nodes, \"dist\": dist, \"y\": y}\n",
    "\n",
    "from torch_geometric.nn import knn_graph\n",
    "data_list = []\n",
    "for instance_name in instances:\n",
    "    y = torch.tensor(instances[instance_name][\"y\"], dtype=torch.float)\n",
    "    x = torch.tensor([instances[instance_name][\"nodes\"][i] for i in range(0, 101)], dtype=torch.float)\n",
    "    pos = []\n",
    "    for i in range(101):\n",
    "        pos.append(instances[instance_name][\"nodes\"][i])\n",
    "    pos = torch.tensor(pos, dtype=torch.double)\n",
    "    # ## filtering by TW, strict\n",
    "    # complete_graph_list = []\n",
    "    # for i in range(101):\n",
    "    #     for j in range(101):\n",
    "    #         if i!=j:\n",
    "    #             try:\n",
    "    #                 if instance_dict[instance_name][i][5] + instance_dict[instance_name][i][6] + loc_dict[i][j] < instance_dict[instance_name][i][5]:\n",
    "    #                     complete_graph_list.append([i,j])\n",
    "    #             except:\n",
    "    #                 continue\n",
    "    # edge_index = torch.tensor(complete_graph_list, dtype=torch.double).t().contiguous()\n",
    "    ## end filtering\n",
    "    data_list.append(Data(x=x, y=y, edge_index = knn_graph(x, 15), pos=pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[101, 2], edge_index=[2, 1308], y=[101, 101], pos=[101, 2], edge_label=[654], edge_label_index=[2, 654]),\n",
       " Data(x=[101, 2], edge_index=[2, 1308], y=[101, 101], pos=[101, 2], edge_label=[76], edge_label_index=[2, 76]),\n",
       " Data(x=[101, 2], edge_index=[2, 1384], y=[101, 101], pos=[101, 2], edge_label=[152], edge_label_index=[2, 152]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "def custom_collate(data_list):\n",
    "    batch = Batch.from_data_list(data_list)\n",
    "\n",
    "    # Manually handle edge_label and edge_label_index if they exist in the data_list\n",
    "    if hasattr(data_list[0], 'edge_label_index'):\n",
    "        edge_label_index_list = [data.edge_label_index for data in data_list]\n",
    "        batch.edge_label_index = torch.cat(edge_label_index_list, dim=1)\n",
    "        \n",
    "    if hasattr(data_list[0], 'edge_label'):\n",
    "        edge_label_list = [data.edge_label for data in data_list]\n",
    "        batch.edge_label = torch.cat(edge_label_list, dim=0)\n",
    "        \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = [g[0] for g in labeled_graphs]\n",
    "val_size = [g[1] for g in labeled_graphs]\n",
    "test_size = [g[2] for g in labeled_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_size, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_size, batch_size=20, shuffle=False)\n",
    "test_loader = DataLoader(test_size, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[2020, 2], edge_index=[2, 25794], y=[2020, 101], pos=[2020, 2], edge_label=[12897], edge_label_index=[2, 12897], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25712], y=[2020, 101], pos=[2020, 2], edge_label=[12856], edge_label_index=[2, 12856], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25696], y=[2020, 101], pos=[2020, 2], edge_label=[12848], edge_label_index=[2, 12848], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25478], y=[2020, 101], pos=[2020, 2], edge_label=[12739], edge_label_index=[2, 12739], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25672], y=[2020, 101], pos=[2020, 2], edge_label=[12836], edge_label_index=[2, 12836], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25806], y=[2020, 101], pos=[2020, 2], edge_label=[12903], edge_label_index=[2, 12903], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25796], y=[2020, 101], pos=[2020, 2], edge_label=[12898], edge_label_index=[2, 12898], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25560], y=[2020, 101], pos=[2020, 2], edge_label=[12780], edge_label_index=[2, 12780], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25612], y=[2020, 101], pos=[2020, 2], edge_label=[12806], edge_label_index=[2, 12806], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25812], y=[2020, 101], pos=[2020, 2], edge_label=[12906], edge_label_index=[2, 12906], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25406], y=[2020, 101], pos=[2020, 2], edge_label=[12703], edge_label_index=[2, 12703], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25576], y=[2020, 101], pos=[2020, 2], edge_label=[12788], edge_label_index=[2, 12788], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25662], y=[2020, 101], pos=[2020, 2], edge_label=[12831], edge_label_index=[2, 12831], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25690], y=[2020, 101], pos=[2020, 2], edge_label=[12845], edge_label_index=[2, 12845], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25770], y=[2020, 101], pos=[2020, 2], edge_label=[12885], edge_label_index=[2, 12885], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25606], y=[2020, 101], pos=[2020, 2], edge_label=[12803], edge_label_index=[2, 12803], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25832], y=[2020, 101], pos=[2020, 2], edge_label=[12916], edge_label_index=[2, 12916], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25636], y=[2020, 101], pos=[2020, 2], edge_label=[12818], edge_label_index=[2, 12818], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25598], y=[2020, 101], pos=[2020, 2], edge_label=[12799], edge_label_index=[2, 12799], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25778], y=[2020, 101], pos=[2020, 2], edge_label=[12889], edge_label_index=[2, 12889], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25776], y=[2020, 101], pos=[2020, 2], edge_label=[12888], edge_label_index=[2, 12888], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25778], y=[2020, 101], pos=[2020, 2], edge_label=[12889], edge_label_index=[2, 12889], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25696], y=[2020, 101], pos=[2020, 2], edge_label=[12848], edge_label_index=[2, 12848], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25710], y=[2020, 101], pos=[2020, 2], edge_label=[12855], edge_label_index=[2, 12855], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25666], y=[2020, 101], pos=[2020, 2], edge_label=[12833], edge_label_index=[2, 12833], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25650], y=[2020, 101], pos=[2020, 2], edge_label=[12825], edge_label_index=[2, 12825], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25354], y=[2020, 101], pos=[2020, 2], edge_label=[12677], edge_label_index=[2, 12677], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25694], y=[2020, 101], pos=[2020, 2], edge_label=[12847], edge_label_index=[2, 12847], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25534], y=[2020, 101], pos=[2020, 2], edge_label=[12767], edge_label_index=[2, 12767], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25762], y=[2020, 101], pos=[2020, 2], edge_label=[12881], edge_label_index=[2, 12881], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25622], y=[2020, 101], pos=[2020, 2], edge_label=[12811], edge_label_index=[2, 12811], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25710], y=[2020, 101], pos=[2020, 2], edge_label=[12855], edge_label_index=[2, 12855], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25718], y=[2020, 101], pos=[2020, 2], edge_label=[12859], edge_label_index=[2, 12859], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25872], y=[2020, 101], pos=[2020, 2], edge_label=[12936], edge_label_index=[2, 12936], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25568], y=[2020, 101], pos=[2020, 2], edge_label=[12784], edge_label_index=[2, 12784], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25746], y=[2020, 101], pos=[2020, 2], edge_label=[12873], edge_label_index=[2, 12873], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25646], y=[2020, 101], pos=[2020, 2], edge_label=[12823], edge_label_index=[2, 12823], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25514], y=[2020, 101], pos=[2020, 2], edge_label=[12757], edge_label_index=[2, 12757], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25714], y=[2020, 101], pos=[2020, 2], edge_label=[12857], edge_label_index=[2, 12857], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25400], y=[2020, 101], pos=[2020, 2], edge_label=[12700], edge_label_index=[2, 12700], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25536], y=[2020, 101], pos=[2020, 2], edge_label=[12768], edge_label_index=[2, 12768], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25752], y=[2020, 101], pos=[2020, 2], edge_label=[12876], edge_label_index=[2, 12876], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25634], y=[2020, 101], pos=[2020, 2], edge_label=[12817], edge_label_index=[2, 12817], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25528], y=[2020, 101], pos=[2020, 2], edge_label=[12764], edge_label_index=[2, 12764], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25554], y=[2020, 101], pos=[2020, 2], edge_label=[12777], edge_label_index=[2, 12777], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25418], y=[2020, 101], pos=[2020, 2], edge_label=[12709], edge_label_index=[2, 12709], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25726], y=[2020, 101], pos=[2020, 2], edge_label=[12863], edge_label_index=[2, 12863], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25758], y=[2020, 101], pos=[2020, 2], edge_label=[12879], edge_label_index=[2, 12879], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25662], y=[2020, 101], pos=[2020, 2], edge_label=[12831], edge_label_index=[2, 12831], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25616], y=[2020, 101], pos=[2020, 2], edge_label=[12808], edge_label_index=[2, 12808], batch=[2020], ptr=[21])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.9940592956542968\n",
      "Epoch 1, Loss: 1.9940592956542968\n",
      "Epoch 2, Loss: 1.9940592956542968\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m adj_dense \u001b[38;5;241m=\u001b[39m adj_dense\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m adj_pred, _ \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m---> 22\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_dense\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\jotape\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jotape\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jotape\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jotape\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3154\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3152\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "# Assume `data_list` contains multiple graphs with `x`, `edge_index` attributes.\n",
    "# data_list = [...] \n",
    "\n",
    "input_dim = 2\n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "model = GraphAutoencoder(input_dim, hidden_dim, output_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        # optimizer.zero_grad()\n",
    "        adj_dense = to_dense_adj(data.edge_index, max_num_nodes=data.num_nodes)[0]\n",
    "        adj_dense = adj_dense.view(-1)\n",
    "        adj_pred, _ = model(data.x, data.edge_index)\n",
    "        loss = criterion(adj_pred.view(-1), adj_dense)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch}, Loss: {total_loss / len(data_list)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
