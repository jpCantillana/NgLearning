{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transform = T.Compose([\n",
    "    T.NormalizeFeatures(),\n",
    "    T.ToDevice(device),\n",
    "    T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.cora.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "path = osp.join(osp.dirname(osp.realpath(\".\")), '..', 'data', 'Planetoid')\n",
    "dataset = Planetoid(path, name='Cora', transform=transform)\n",
    "# After applying the `RandomLinkSplit` transform, the data is transformed from\n",
    "# a data object to a list of tuples (train_data, val_data, test_data), with\n",
    "# each element representing the corresponding split.\n",
    "train_data, val_data, test_data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 8976], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], edge_label=[4488], edge_label_index=[2, 4488])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge_labels(graph):\n",
    "    transform = T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False)\n",
    "    return transform(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_graphs = [add_edge_labels(graph) for graph in data_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[101, 2], edge_index=[2, 1308], y=[101, 101], pos=[101, 2], edge_label=[654], edge_label_index=[2, 654]),\n",
       " Data(x=[101, 2], edge_index=[2, 1308], y=[101, 101], pos=[101, 2], edge_label=[76], edge_label_index=[2, 76]),\n",
       " Data(x=[101, 2], edge_index=[2, 1384], y=[101, 101], pos=[101, 2], edge_label=[152], edge_label_index=[2, 152]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 30300], y=[2020, 101], pos=[2020, 2], batch=[2020], ptr=[21])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(data_list[0].num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "\n",
    "        # We perform a new round of negative sampling for every training epoch:\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=batch.edge_index, num_nodes=batch.num_nodes,\n",
    "            num_neg_samples=batch.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "        # Concat positive and negative edge indices.\n",
    "        edge_label_index = torch.cat(\n",
    "            [batch.edge_label_index, neg_edge_index],\n",
    "            dim=-1,\n",
    "        )\n",
    "        # Label for positive edges: 1, for negative edges: 0.\n",
    "        edge_label = torch.cat([\n",
    "            batch.edge_label,\n",
    "            batch.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "        ], dim=0)\n",
    "\n",
    "        # Note: The model is trained in a supervised manner using the given\n",
    "        # `edge_label_index` and `edge_label` targets.\n",
    "        out = model.decode(z, edge_label_index).view(-1)\n",
    "        loss = criterion(out, edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    all_out = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in loader:\n",
    "        z = model.encode(batch.x, batch.edge_index)\n",
    "        out = model.decode(z, batch.edge_label_index).view(-1).sigmoid()\n",
    "        all_out.append(out.cpu().numpy())\n",
    "        all_labels.append(batch.edge_label.cpu().numpy())\n",
    "\n",
    "    all_out = np.concatenate(all_out)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return roc_auc_score(all_labels, all_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 70.0116, Val: 0.8504, Test: 0.8517\n",
      "Epoch: 002, Loss: 1.0224, Val: 0.8688, Test: 0.8703\n",
      "Epoch: 003, Loss: 0.6042, Val: 0.8746, Test: 0.8761\n",
      "Epoch: 004, Loss: 0.5614, Val: 0.8758, Test: 0.8773\n",
      "Epoch: 005, Loss: 0.5477, Val: 0.8868, Test: 0.8883\n",
      "Epoch: 006, Loss: 0.5367, Val: 0.9040, Test: 0.9057\n",
      "Epoch: 007, Loss: 0.5257, Val: 0.9195, Test: 0.9211\n",
      "Epoch: 008, Loss: 0.5165, Val: 0.9262, Test: 0.9275\n",
      "Epoch: 009, Loss: 0.5119, Val: 0.9292, Test: 0.9305\n",
      "Epoch: 010, Loss: 0.5083, Val: 0.9288, Test: 0.9299\n",
      "Epoch: 011, Loss: 0.5086, Val: 0.9314, Test: 0.9325\n",
      "Epoch: 012, Loss: 0.5069, Val: 0.9318, Test: 0.9329\n",
      "Epoch: 013, Loss: 0.5060, Val: 0.9330, Test: 0.9341\n",
      "Epoch: 014, Loss: 0.5044, Val: 0.9331, Test: 0.9341\n",
      "Epoch: 015, Loss: 0.5042, Val: 0.9339, Test: 0.9349\n",
      "Epoch: 016, Loss: 0.5051, Val: 0.9327, Test: 0.9337\n",
      "Epoch: 017, Loss: 0.5028, Val: 0.9329, Test: 0.9339\n",
      "Epoch: 018, Loss: 0.5063, Val: 0.9320, Test: 0.9330\n",
      "Epoch: 019, Loss: 0.5035, Val: 0.9343, Test: 0.9353\n",
      "Epoch: 020, Loss: 0.5040, Val: 0.9329, Test: 0.9338\n",
      "Epoch: 021, Loss: 0.5033, Val: 0.9338, Test: 0.9348\n",
      "Epoch: 022, Loss: 0.5036, Val: 0.9341, Test: 0.9351\n",
      "Epoch: 023, Loss: 0.5021, Val: 0.9348, Test: 0.9357\n",
      "Epoch: 024, Loss: 0.5047, Val: 0.9341, Test: 0.9351\n",
      "Epoch: 025, Loss: 0.5028, Val: 0.9346, Test: 0.9356\n",
      "Epoch: 026, Loss: 0.5032, Val: 0.9345, Test: 0.9355\n",
      "Epoch: 027, Loss: 0.5033, Val: 0.9347, Test: 0.9357\n",
      "Epoch: 028, Loss: 0.5029, Val: 0.9331, Test: 0.9340\n",
      "Epoch: 029, Loss: 0.5025, Val: 0.9339, Test: 0.9349\n",
      "Epoch: 030, Loss: 0.5033, Val: 0.9342, Test: 0.9352\n",
      "Epoch: 031, Loss: 0.5031, Val: 0.9346, Test: 0.9356\n",
      "Epoch: 032, Loss: 0.5017, Val: 0.9351, Test: 0.9360\n",
      "Epoch: 033, Loss: 0.5029, Val: 0.9342, Test: 0.9352\n",
      "Epoch: 034, Loss: 0.5024, Val: 0.9353, Test: 0.9362\n",
      "Epoch: 035, Loss: 0.5012, Val: 0.9351, Test: 0.9360\n",
      "Epoch: 036, Loss: 0.5021, Val: 0.9354, Test: 0.9363\n",
      "Epoch: 037, Loss: 0.5005, Val: 0.9349, Test: 0.9359\n",
      "Epoch: 038, Loss: 0.5020, Val: 0.9353, Test: 0.9362\n",
      "Epoch: 039, Loss: 0.5016, Val: 0.9356, Test: 0.9365\n",
      "Epoch: 040, Loss: 0.5023, Val: 0.9355, Test: 0.9365\n",
      "Epoch: 041, Loss: 0.5015, Val: 0.9356, Test: 0.9366\n",
      "Epoch: 042, Loss: 0.5010, Val: 0.9358, Test: 0.9367\n",
      "Epoch: 043, Loss: 0.5006, Val: 0.9358, Test: 0.9368\n",
      "Epoch: 044, Loss: 0.5012, Val: 0.9356, Test: 0.9366\n",
      "Epoch: 045, Loss: 0.5015, Val: 0.9358, Test: 0.9367\n",
      "Epoch: 046, Loss: 0.5023, Val: 0.9340, Test: 0.9350\n",
      "Epoch: 047, Loss: 0.5001, Val: 0.9359, Test: 0.9367\n",
      "Epoch: 048, Loss: 0.5005, Val: 0.9360, Test: 0.9369\n",
      "Epoch: 049, Loss: 0.4998, Val: 0.9361, Test: 0.9371\n",
      "Epoch: 050, Loss: 0.5026, Val: 0.9333, Test: 0.9342\n",
      "Epoch: 051, Loss: 0.5022, Val: 0.9347, Test: 0.9355\n",
      "Epoch: 052, Loss: 0.5003, Val: 0.9362, Test: 0.9371\n",
      "Epoch: 053, Loss: 0.5009, Val: 0.9363, Test: 0.9372\n",
      "Epoch: 054, Loss: 0.4998, Val: 0.9361, Test: 0.9368\n",
      "Epoch: 055, Loss: 0.4994, Val: 0.9344, Test: 0.9351\n",
      "Epoch: 056, Loss: 0.5008, Val: 0.9364, Test: 0.9371\n",
      "Epoch: 057, Loss: 0.5017, Val: 0.9363, Test: 0.9372\n",
      "Epoch: 058, Loss: 0.5001, Val: 0.9355, Test: 0.9364\n",
      "Epoch: 059, Loss: 0.5026, Val: 0.9361, Test: 0.9371\n",
      "Epoch: 060, Loss: 0.5003, Val: 0.9358, Test: 0.9366\n",
      "Epoch: 061, Loss: 0.4997, Val: 0.9364, Test: 0.9373\n",
      "Epoch: 062, Loss: 0.5000, Val: 0.9359, Test: 0.9366\n",
      "Epoch: 063, Loss: 0.4991, Val: 0.9367, Test: 0.9377\n",
      "Epoch: 064, Loss: 0.4992, Val: 0.9365, Test: 0.9372\n",
      "Epoch: 065, Loss: 0.4998, Val: 0.9366, Test: 0.9376\n",
      "Epoch: 066, Loss: 0.4996, Val: 0.9365, Test: 0.9374\n",
      "Epoch: 067, Loss: 0.4983, Val: 0.9353, Test: 0.9360\n",
      "Epoch: 068, Loss: 0.4988, Val: 0.9362, Test: 0.9371\n",
      "Epoch: 069, Loss: 0.5005, Val: 0.9354, Test: 0.9361\n",
      "Epoch: 070, Loss: 0.4986, Val: 0.9369, Test: 0.9377\n",
      "Epoch: 071, Loss: 0.4987, Val: 0.9375, Test: 0.9383\n",
      "Epoch: 072, Loss: 0.5007, Val: 0.9373, Test: 0.9382\n",
      "Epoch: 073, Loss: 0.5004, Val: 0.9375, Test: 0.9384\n",
      "Epoch: 074, Loss: 0.4985, Val: 0.9379, Test: 0.9387\n",
      "Epoch: 075, Loss: 0.4996, Val: 0.9369, Test: 0.9378\n",
      "Epoch: 076, Loss: 0.4986, Val: 0.9384, Test: 0.9394\n",
      "Epoch: 077, Loss: 0.5005, Val: 0.9382, Test: 0.9391\n",
      "Epoch: 078, Loss: 0.4982, Val: 0.9373, Test: 0.9383\n",
      "Epoch: 079, Loss: 0.4984, Val: 0.9383, Test: 0.9391\n",
      "Epoch: 080, Loss: 0.4976, Val: 0.9381, Test: 0.9391\n",
      "Epoch: 081, Loss: 0.4982, Val: 0.9382, Test: 0.9390\n",
      "Epoch: 082, Loss: 0.4998, Val: 0.9385, Test: 0.9392\n",
      "Epoch: 083, Loss: 0.4997, Val: 0.9375, Test: 0.9383\n",
      "Epoch: 084, Loss: 0.4984, Val: 0.9391, Test: 0.9400\n",
      "Epoch: 085, Loss: 0.4988, Val: 0.9351, Test: 0.9358\n",
      "Epoch: 086, Loss: 0.4987, Val: 0.9388, Test: 0.9399\n",
      "Epoch: 087, Loss: 0.4976, Val: 0.9385, Test: 0.9396\n",
      "Epoch: 088, Loss: 0.4978, Val: 0.9402, Test: 0.9411\n",
      "Epoch: 089, Loss: 0.4968, Val: 0.9369, Test: 0.9377\n",
      "Epoch: 090, Loss: 0.4974, Val: 0.9388, Test: 0.9396\n",
      "Epoch: 091, Loss: 0.4986, Val: 0.9389, Test: 0.9399\n",
      "Epoch: 092, Loss: 0.4975, Val: 0.9398, Test: 0.9412\n",
      "Epoch: 093, Loss: 0.4996, Val: 0.9386, Test: 0.9396\n",
      "Epoch: 094, Loss: 0.4972, Val: 0.9398, Test: 0.9409\n",
      "Epoch: 095, Loss: 0.4982, Val: 0.9400, Test: 0.9412\n",
      "Epoch: 096, Loss: 0.4955, Val: 0.9411, Test: 0.9424\n",
      "Epoch: 097, Loss: 0.4974, Val: 0.9403, Test: 0.9415\n",
      "Epoch: 098, Loss: 0.4979, Val: 0.9411, Test: 0.9421\n",
      "Epoch: 099, Loss: 0.4934, Val: 0.9426, Test: 0.9436\n",
      "Epoch: 100, Loss: 0.4973, Val: 0.9435, Test: 0.9445\n",
      "Final Test: 0.9445\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Loop\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train(train_loader)\n",
    "    val_auc = test(val_loader)\n",
    "    test_auc = test(test_loader)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "z = model.encode(train_size[0].x, train_size[0].edge_index)\n",
    "final_edge_index = model.decode_all(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0975,  0.0965,  0.1179,  ..., -0.2019, -0.0823,  0.2832],\n",
       "        [ 0.1081, -0.1024,  0.2862,  ...,  0.0125, -0.0514, -0.0633],\n",
       "        [ 0.0154, -0.0206,  0.2033,  ..., -0.2354, -0.1704,  0.2083],\n",
       "        ...,\n",
       "        [ 0.2875, -0.0498, -0.3933,  ..., -0.0443,  0.0819, -0.1261],\n",
       "        [ 0.0784, -0.0241,  0.2030,  ...,  0.1055,  0.0498, -0.2083],\n",
       "        [ 0.3449, -0.1079, -0.2666,  ..., -0.3180,  0.0281, -0.0787]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "fei = final_edge_index.tolist()\n",
    "edges_pred = {k:[] for k in range(101)}\n",
    "edges_pred_inv = {k:[] for k in range(101)}\n",
    "for i in range(len(fei[0])):\n",
    "    edges_pred[fei[0][i]].append(fei[1][i])\n",
    "    edges_pred_inv[fei[1][i]].append(fei[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts0 = train_size[0].edge_index.tolist()\n",
    "edges = {k:[] for k in range(101)}\n",
    "edges_inv = {k:[] for k in range(101)}\n",
    "for i in range(len(ts0[0])):\n",
    "    edges[ts0[0][i]].append(ts0[1][i])\n",
    "    edges_inv[ts0[1][i]].append(ts0[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72, 68, 22, 88]\n",
      "[72, 68, 22, 88]\n"
     ]
    }
   ],
   "source": [
    "print(edges[0])\n",
    "print(edges_inv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "[0, 1, 2, 4, 5, 7, 12, 16, 21, 22, 24, 26, 30, 33, 35, 36, 38, 39, 42, 45, 47, 48, 50, 54, 57, 58, 59, 67, 68, 72, 76, 79, 81, 84, 87, 88, 89, 94]\n"
     ]
    }
   ],
   "source": [
    "print(len(edges_pred[0]))\n",
    "print(edges_pred_inv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_raw = model.encode(data_list[0].x, data_list[0].edge_index)\n",
    "final_edge_index = model.decode_all(z_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0962,  0.0431,  0.1419,  ..., -0.2443, -0.1488,  0.2129],\n",
       "        [ 0.1395, -0.0889,  0.2966,  ..., -0.0376, -0.0449, -0.0761],\n",
       "        [-0.0483, -0.1029,  0.2274,  ..., -0.1108, -0.2028,  0.1227],\n",
       "        ...,\n",
       "        [ 0.3060, -0.0592, -0.4395,  ..., -0.1580,  0.1210, -0.1487],\n",
       "        [ 0.0710,  0.0184,  0.2128,  ...,  0.0994,  0.0470, -0.2367],\n",
       "        [ 0.3488, -0.0906, -0.3668,  ..., -0.2929,  0.0824, -0.1348]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ..., 100, 100, 100],\n",
       "        [  0,   1,   2,  ...,  97,  98, 100]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 22,  68,  88,  ...,  97,  92,  53],\n",
       "        [  0,   0,   0,  ..., 100, 100, 100]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0].edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "fei = final_edge_index.tolist()\n",
    "edges_pred = {k:[] for k in range(101)}\n",
    "edges_pred_inv = {k:[] for k in range(101)}\n",
    "for i in range(len(fei[0])):\n",
    "    edges_pred[fei[0][i]].append(fei[1][i])\n",
    "    edges_pred_inv[fei[1][i]].append(fei[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts0 = data_list[0].edge_index.tolist()\n",
    "edges = {k:[] for k in range(101)}\n",
    "edges_inv = {k:[] for k in range(101)}\n",
    "for i in range(len(ts0[0])):\n",
    "    edges[ts0[0][i]].append(ts0[1][i])\n",
    "    edges_inv[ts0[1][i]].append(ts0[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22, 54, 68, 72, 88]\n",
      "[22, 68, 88, 54, 72, 12, 45, 24, 30, 57, 5, 26, 7, 47, 2]\n"
     ]
    }
   ],
   "source": [
    "print(edges[0])\n",
    "print(edges_inv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 12, 14, 15, 16, 19, 21, 22, 24, 26, 28, 30, 31, 33, 35, 36, 37, 38, 39, 45, 47, 48, 54, 55, 56, 57, 58, 62, 63, 64, 67, 68, 70, 72, 76, 78, 79, 81, 84, 87, 88, 89, 90, 92, 94, 95, 97, 100]\n",
      "[0, 1, 2, 3, 4, 5, 7, 8, 9, 12, 14, 15, 16, 19, 21, 22, 24, 26, 28, 30, 31, 33, 35, 36, 37, 38, 39, 45, 47, 48, 54, 55, 56, 57, 58, 62, 63, 64, 67, 68, 70, 72, 76, 78, 79, 81, 84, 87, 88, 89, 90, 92, 94, 95, 97, 100]\n"
     ]
    }
   ],
   "source": [
    "print(edges_pred[0])\n",
    "print(edges_pred_inv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 3, 5}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = {1,3,5}\n",
    "b = {1,2,3,4,5}\n",
    "a.intersection(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_dict = {}\n",
    "cnt = 0\n",
    "for graph in data_list:\n",
    "    z_raw = model.encode(graph.x, graph.edge_index)\n",
    "    final_edge_index = model.decode_all(z_raw)\n",
    "    fei = final_edge_index.tolist()\n",
    "    edges_pred = {k:[] for k in range(101)}\n",
    "    edges_pred_inv = {k:[] for k in range(101)}\n",
    "    for i in range(len(fei[0])):\n",
    "        edges_pred[fei[0][i]].append(fei[1][i])\n",
    "        edges_pred_inv[fei[1][i]].append(fei[0][i])\n",
    "    ts0 = graph.edge_index.tolist()\n",
    "    edges = {k:[] for k in range(101)}\n",
    "    edges_inv = {k:[] for k in range(101)}\n",
    "    for i in range(len(ts0[0])):\n",
    "        edges[ts0[0][i]].append(ts0[1][i])\n",
    "        edges_inv[ts0[1][i]].append(ts0[0][i])\n",
    "    originals = {}\n",
    "    predictions = {}\n",
    "    for i in range(101):\n",
    "        originals[i] = set(edges[i] + edges_inv[i])\n",
    "        predictions[i] = set(edges_pred[i] + edges_pred_inv[i])\n",
    "    graph_dict[cnt] = {\"real\": originals, \"preds\": predictions}\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_dict = {}\n",
    "true_positives = []\n",
    "false_positives = []\n",
    "true_negatives = []\n",
    "false_negatives = []\n",
    "for key in graph_dict:\n",
    "    real = graph_dict[key][\"real\"]\n",
    "    pred = graph_dict[key][\"preds\"]\n",
    "    node_matrix = {}\n",
    "    for i in range(101):\n",
    "        tp = len(pred[i].intersection(real[i]))\n",
    "        fp = len(pred[i] - real[i])\n",
    "        real_neg = set([j for j in range(101)]) - {i} - real[i]\n",
    "        pred_neg = set([j for j in range(101)]) - {i} - pred[i]\n",
    "        tn = len(pred_neg.intersection(real_neg))\n",
    "        fn = len(pred_neg - real_neg)\n",
    "        total = tp + fp + tn + fn\n",
    "        node_matrix[i] = {\"tp\": tp, \"fp\": fp, \"tn\": tn, \"fn\": fn, \"total\": total}\n",
    "        true_positives.append(tp/total)\n",
    "        false_positives.append(fp/total)\n",
    "        true_negatives.append(tn/total)\n",
    "        false_negatives.append(fn/total)\n",
    "    confusion_dict[key] = node_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true positives mean=0.17, stdev=0.03\n",
      "false positives mean=0.27, stdev=0.11\n",
      "true negatives mean=0.56, stdev=0.12\n",
      "false negatives mean=0.00, stdev=0.00\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean, stdev\n",
    "print(\"true positives mean={0:.2f}, stdev={1:.2f}\".format(mean(true_positives), stdev(true_positives)))\n",
    "print(\"false positives mean={0:.2f}, stdev={1:.2f}\".format(mean(false_positives), stdev(false_positives)))\n",
    "print(\"true negatives mean={0:.2f}, stdev={1:.2f}\".format(mean(true_negatives), stdev(true_negatives)))\n",
    "print(\"false negatives mean={0:.2f}, stdev={1:.2f}\".format(mean(false_negatives), stdev(false_negatives)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = graph_dict[0][\"real\"][0]\n",
    "b = graph_dict[0][\"preds\"][0]\n",
    "len(a.intersection(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "data_raw_dict = {\n",
    "    \"positives\": [],\n",
    "    \"negatives\": []\n",
    "}\n",
    "cnt = 0\n",
    "pos_cnt = 0\n",
    "neg_cnt = 0\n",
    "for graph in data_list:\n",
    "    neg_cnt = 0\n",
    "    ng_matrix = graph.y.tolist()\n",
    "    encoding_matrix = model.encode(graph.x, graph.edge_index).tolist()\n",
    "    for i in range(101):\n",
    "        for j in sample(range(101), 30):\n",
    "            if i == j:\n",
    "                # if pos_cnt < 80000:\n",
    "                #     data_raw_dict[\"positives\"].append(encoding_matrix[i]+encoding_matrix[i])\n",
    "                #     pos_cnt += 1\n",
    "                continue\n",
    "            else:\n",
    "                if ng_matrix[i][j] > 0.5:\n",
    "                    if pos_cnt < 80000:\n",
    "                        data_raw_dict[\"positives\"].append(encoding_matrix[i]+encoding_matrix[j]+[1])\n",
    "                        pos_cnt += 1\n",
    "                else:\n",
    "                    if pos_cnt < 80000 and neg_cnt < 1010:\n",
    "                        data_raw_dict[\"negatives\"].append(encoding_matrix[i]+encoding_matrix[j]+[0])\n",
    "                        neg_cnt += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tensor = data_raw_dict[\"positives\"][:5000] + data_raw_dict[\"negatives\"][:5000]\n",
    "main_tensor = torch.tensor(pre_tensor, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1596, -0.1800, -0.2464,  ...,  0.1065,  0.0275,  1.0000],\n",
       "        [ 0.1581,  0.1355,  0.1712,  ..., -0.0182, -0.0102,  1.0000],\n",
       "        [-0.0444, -0.1654, -0.1269,  ..., -0.1918, -0.1444,  1.0000],\n",
       "        ...,\n",
       "        [-0.0811, -0.2015, -0.0910,  ..., -0.2468, -0.1751,  0.0000],\n",
       "        [-0.0811, -0.2015, -0.0910,  ...,  0.1364,  0.2510,  0.0000],\n",
       "        [-0.0811, -0.2015, -0.0910,  ..., -0.2437, -0.1129,  0.0000]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_tensor = main_tensor[torch.randperm(main_tensor.size()[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = main_tensor[:,-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = main_tensor[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wide(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(128, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.output = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.hidden(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(128, 128)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(128, 128)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    " \n",
    "def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    " \n",
    "    n_epochs = 20   # number of epochs to run\n",
    "    batch_size = 10  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    " \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (wide): 0.94\n",
      "Accuracy (wide): 0.95\n",
      "Accuracy (wide): 0.94\n",
      "Accuracy (wide): 0.94\n",
      "Accuracy (wide): 0.94\n",
      "Accuracy (deep): 0.95\n",
      "Accuracy (deep): 0.95\n",
      "Accuracy (deep): 0.95\n",
      "Accuracy (deep): 0.96\n",
      "Accuracy (deep): 0.95\n",
      "Wide: 94.21% (+/- 0.52%)\n",
      "Deep: 95.26% (+/- 0.37%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "# train-test split: Hold out the test set for final model evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, labels, train_size=0.7, shuffle=True)\n",
    " \n",
    "# define 5-fold cross validation test harness\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "cv_scores_wide = []\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    # create model, train, and get accuracy\n",
    "    model = Wide()\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test])\n",
    "    print(\"Accuracy (wide): %.2f\" % acc)\n",
    "    cv_scores_wide.append(acc)\n",
    "cv_scores_deep = []\n",
    "for train, test in kfold.split(X_train, y_train):\n",
    "    # create model, train, and get accuracy\n",
    "    model = Deep()\n",
    "    acc = model_train(model, X_train[train], y_train[train], X_train[test], y_train[test])\n",
    "    print(\"Accuracy (deep): %.2f\" % acc)\n",
    "    cv_scores_deep.append(acc)\n",
    " \n",
    "# evaluate the model\n",
    "wide_acc = np.mean(cv_scores_wide)\n",
    "wide_std = np.std(cv_scores_wide)\n",
    "deep_acc = np.mean(cv_scores_deep)\n",
    "deep_std = np.std(cv_scores_deep)\n",
    "print(\"Wide: %.2f%% (+/- %.2f%%)\" % (wide_acc*100, wide_std*100))\n",
    "print(\"Deep: %.2f%% (+/- %.2f%%)\" % (deep_acc*100, deep_std*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrain a deep model\n",
      "Final model accuracy: 95.03%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# rebuild model with full set of training data\n",
    "if wide_acc > deep_acc:\n",
    "    print(\"Retrain a wide model\")\n",
    "    model = Wide()\n",
    "else:\n",
    "    print(\"Retrain a deep model\")\n",
    "    model = Deep()\n",
    "acc = model_train(model, X_train, y_train, X_test, y_test)\n",
    "print(f\"Final model accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.14186503  0.06852816  0.13882583  0.18554422  0.01259524  0.17407712\n",
      " -0.13004386 -0.05792312  0.2794271  -0.02302442  0.23547888  0.2619889\n",
      "  0.03080954  0.01906595  0.12538412 -0.05007584 -0.1969449   0.26221353\n",
      " -0.14023745 -0.17518337 -0.25760165  0.32017156  0.19400236 -0.21908599\n",
      "  0.24090998 -0.01987933  0.14625137  0.11163279  0.13615549  0.0862607\n",
      "  0.08827582 -0.05215658 -0.00360495  0.01262195 -0.0599436   0.44187227\n",
      "  0.1084906  -0.03968846 -0.19452572  0.01262102  0.29458293  0.05522395\n",
      "  0.00714007  0.3330657  -0.02873032  0.05573579 -0.09651121 -0.15342638\n",
      " -0.05340988 -0.1161788   0.12370549  0.0268348  -0.10383974 -0.15232193\n",
      " -0.0115384  -0.11657755  0.30440044 -0.19080487  0.27328292  0.0676147\n",
      " -0.03920259  0.00676232  0.03846721  0.02173189  0.03840839 -0.03786739\n",
      " -0.5602042   0.10600065 -0.01190336 -0.42612877  0.01708128  0.05423341\n",
      "  0.38217825  0.10992724 -0.20942265 -0.21930662  0.02979036 -0.3321424\n",
      "  0.03305952 -0.00558868  0.2711308  -0.12160604  0.1749534   0.12622024\n",
      "  0.16882296 -0.01289244  0.1866878   0.08142387 -0.17978352 -0.15163347\n",
      " -0.4345257  -0.04918301 -0.00180659 -0.24956751 -0.26065767  0.01321465\n",
      " -0.09157915  0.11700726  0.02186904 -0.13865554 -0.34324294  0.45914078\n",
      "  0.5243212  -0.10581863 -0.463681   -0.2682439   0.10479605  0.0271978\n",
      " -0.15889522  0.06118536 -0.27632838  0.13433452  0.00080679  0.1889981\n",
      " -0.10607117 -0.12842143 -0.28621882 -0.19433647  0.08402333  0.22848156\n",
      " -0.01299971 -0.15458488 -0.21897285 -0.17754284 -0.18667059 -0.2018998\n",
      "  0.10700446 -0.08016045] -> [3.3165654e-07] (expected [0.])\n",
      "[ 0.03353564  0.11679098  0.19287638 -0.17337807 -0.0959174   0.14475009\n",
      " -0.00510366 -0.13391146 -0.21067967  0.131865   -0.2749365   0.00540909\n",
      "  0.22027475  0.27540663 -0.2949857  -0.2646668   0.24873874 -0.2418474\n",
      "  0.00308665 -0.12606327  0.13826244 -0.15953577 -0.00324002  0.08895461\n",
      "  0.19844136 -0.10083875  0.00205334  0.05472086 -0.33400172  0.1507823\n",
      " -0.14467809 -0.08920123 -0.3617322  -0.0324921   0.09687407 -0.23991822\n",
      "  0.13599628 -0.40213287  0.11919363  0.2188412   0.0750916  -0.07538503\n",
      "  0.06319721 -0.20921463  0.2994177  -0.2950789   0.28162682  0.1803806\n",
      "  0.336698    0.02111876 -0.06137772 -0.06756574  0.16631684  0.38191876\n",
      "  0.28791353  0.34044102 -0.40578228  0.19085693 -0.26874495 -0.24568272\n",
      " -0.02580123 -0.15481442  0.16226132  0.19460087  0.03353564  0.11679098\n",
      "  0.19287638 -0.17337808 -0.0959174   0.14475012 -0.00510366 -0.13391148\n",
      " -0.21067967  0.131865   -0.2749365   0.00540909  0.22027478  0.2754066\n",
      " -0.29498568 -0.26466677  0.24873874 -0.2418474   0.00308665 -0.12606327\n",
      "  0.13826244 -0.15953575 -0.00324002  0.08895461  0.19844137 -0.10083875\n",
      "  0.00205334  0.05472086 -0.33400172  0.1507823  -0.1446781  -0.08920122\n",
      " -0.3617322  -0.0324921   0.09687407 -0.23991822  0.13599628 -0.40213287\n",
      "  0.11919363  0.21884122  0.0750916  -0.07538503  0.06319721 -0.20921463\n",
      "  0.2994177  -0.29507884  0.28162682  0.1803806   0.336698    0.02111875\n",
      " -0.06137772 -0.06756575  0.16631684  0.38191876  0.28791353  0.340441\n",
      " -0.4057824   0.19085693 -0.26874495 -0.24568269 -0.02580123 -0.15481444\n",
      "  0.16226132  0.19460088] -> [0.9989458] (expected [1.])\n",
      "[-0.14115433 -0.10783049 -0.28401458 -0.08432908  0.2404579  -0.20822221\n",
      "  0.00237882  0.22155377  0.05253005  0.23049296 -0.17625183  0.06048298\n",
      " -0.06918218 -0.00180507  0.04671114  0.13511536  0.1701936  -0.00932748\n",
      " -0.0822749   0.13510747  0.08974586 -0.11428183 -0.00979148  0.21726458\n",
      " -0.10987793 -0.02541266 -0.01955691 -0.09723103 -0.18951279 -0.08144546\n",
      "  0.17244059 -0.01283638 -0.24558814  0.01970039  0.12135711 -0.03017953\n",
      " -0.11006145  0.19719176  0.02164143  0.00906374 -0.10124009  0.08473267\n",
      " -0.04723351  0.20447949  0.09207555  0.26498404 -0.15776245 -0.04032233\n",
      "  0.07071117 -0.07491378 -0.10516243 -0.27452293  0.07479317 -0.1736921\n",
      "  0.20935112 -0.14007722  0.10022418 -0.19139917 -0.20520768  0.02106983\n",
      "  0.12651294 -0.06313206  0.15880913  0.13503361 -0.12114603 -0.09454441\n",
      " -0.36076194 -0.08164616  0.20183665 -0.26752275  0.0302114   0.21313404\n",
      "  0.10873745  0.2689405  -0.23565629  0.0109389  -0.04476837 -0.03482216\n",
      "  0.0444909   0.11255007  0.22404814 -0.04897895 -0.06680503  0.15345173\n",
      "  0.11023723 -0.08916309  0.01117147  0.21682267 -0.1070141  -0.06358799\n",
      " -0.08886579 -0.08125781 -0.19352187 -0.07072163  0.10127766 -0.00920687\n",
      " -0.2757879   0.04172735  0.09997265 -0.05371414 -0.15716289  0.25209224\n",
      "  0.12088498  0.00601916 -0.19405177  0.06568922 -0.02650766  0.16219792\n",
      "  0.08590364  0.27677897 -0.16572031  0.01311941  0.06312685 -0.05385396\n",
      " -0.13785812 -0.2768981   0.05128068 -0.18292344  0.21998455 -0.08300679\n",
      "  0.04612941 -0.20081328 -0.2786482  -0.03457914  0.0823155  -0.08509164\n",
      "  0.16809613  0.10269734] -> [0.99016047] (expected [1.])\n",
      "[ 0.11080979  0.04120329  0.17338519  0.18194467  0.02754094  0.15623811\n",
      " -0.15522829 -0.0467741   0.2383516  -0.08696407  0.3265075   0.27336812\n",
      " -0.03506976 -0.04825282  0.12024263 -0.00408031 -0.21750863  0.28160778\n",
      " -0.12012137 -0.14925627 -0.20488457  0.2538733   0.17838465 -0.139622\n",
      "  0.1534499   0.09128252  0.16084528  0.0927141   0.1801832   0.05444746\n",
      "  0.13242377 -0.04556039  0.02438815 -0.0220925  -0.02281136  0.4336305\n",
      "  0.13655248 -0.01272186 -0.30137935  0.00078721  0.40630668  0.1089442\n",
      " -0.04044884  0.4375951  -0.02161244  0.08767369 -0.16137712 -0.26015067\n",
      " -0.04581486 -0.11282893  0.14217791 -0.03529869 -0.04417313 -0.18787307\n",
      "  0.07135707 -0.16079985  0.36365622 -0.1744317   0.27395475  0.14356032\n",
      " -0.0214102  -0.05642255  0.0366549   0.10016081  0.02962244 -0.01249834\n",
      "  0.16430248  0.11103635  0.10709368  0.11234025 -0.12051341  0.01440383\n",
      "  0.14001206 -0.12481149  0.33483416  0.26269168 -0.13234133 -0.05652448\n",
      "  0.10238994  0.05583902 -0.18158653  0.27210417 -0.07591772 -0.11103193\n",
      " -0.1419235   0.15828365  0.09338731 -0.02998484  0.07800993  0.1616323\n",
      "  0.16235714 -0.00356464  0.12343714 -0.02626253  0.20772237 -0.03137391\n",
      "  0.03927567 -0.04842448  0.02488137  0.3553425   0.10511179  0.03131201\n",
      " -0.37766796  0.00425379  0.44097963  0.08891279 -0.09788162  0.47544003\n",
      " -0.02617528  0.10820749 -0.20292856 -0.36238974  0.01491658 -0.11103696\n",
      "  0.09758981 -0.08842154  0.0205024  -0.23011616  0.14023511 -0.23986979\n",
      "  0.39586726 -0.1271061   0.24464099  0.16636223  0.03659898 -0.081406\n",
      "  0.06727853  0.175006  ] -> [0.95412403] (expected [1.])\n",
      "[-0.17500156 -0.06338894 -0.14911912 -0.13674462  0.3236667  -0.04293031\n",
      " -0.0643958   0.24854276 -0.04603413  0.32416028 -0.3185304   0.28799617\n",
      "  0.02377248  0.2675091  -0.09670237  0.06126794  0.18187223  0.13904661\n",
      " -0.12378078  0.04339919  0.06592757 -0.08826151  0.00479638  0.19473498\n",
      "  0.05431283 -0.01594496  0.10609731 -0.08288008 -0.28959125 -0.00763009\n",
      "  0.20163785 -0.04547216 -0.44958785  0.02030304  0.10942588  0.00369418\n",
      " -0.00854763  0.03727508  0.01267597  0.12707764  0.11424128  0.03307569\n",
      " -0.03837093  0.26253957  0.29294035  0.20374374 -0.03852111 -0.03543169\n",
      "  0.25387603 -0.09148506 -0.11168626 -0.31069896  0.1774775  -0.04483124\n",
      "  0.31546044 -0.11930282 -0.00698926 -0.21234132 -0.21135195  0.07283526\n",
      "  0.16067699 -0.01059658  0.23192269  0.353885   -0.14514244 -0.1372714\n",
      " -0.05088608 -0.01582127  0.20069897 -0.08496233 -0.05569597  0.13415366\n",
      "  0.01489249 -0.06725265  0.2208201   0.05624682 -0.21208474 -0.12919453\n",
      "  0.12771489  0.21785241 -0.05339695  0.0721686  -0.04051306  0.0993131\n",
      " -0.02188624 -0.1441187  -0.05219789  0.18285322 -0.18679549  0.10410434\n",
      "  0.08638961 -0.14956044  0.00565006 -0.16505642  0.3059265  -0.03576941\n",
      "  0.0828545  -0.04217258  0.14328249  0.07839806  0.0093861   0.11230066\n",
      " -0.2682491  -0.08886781  0.15794453  0.1402083  -0.08754495  0.34683308\n",
      " -0.04956993  0.15654333 -0.20550272 -0.26527107  0.00445558 -0.03151682\n",
      "  0.01756527 -0.1699155   0.00460204 -0.21589589  0.08637704 -0.26294068\n",
      "  0.3983011  -0.12977204  0.12051128  0.16438238  0.14971039 -0.04842227\n",
      "  0.07113659  0.07681896] -> [0.00476029] (expected [0.])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Test out inference with 5 samples\n",
    "    for i in range(5):\n",
    "        y_pred = model(X_test[i:i+1])\n",
    "        print(f\"{X_test[i].numpy()} -> {y_pred[0].numpy()} (expected {y_test[i].numpy()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now a chatgpt example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GNNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DotProductDecoder, self).__init__()\n",
    "\n",
    "    def forward(self, z):\n",
    "        adj_pred = torch.sigmoid(torch.matmul(z, z.t()))\n",
    "        return adj_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphAutoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphAutoencoder, self).__init__()\n",
    "        self.encoder = GNNEncoder(input_dim, hidden_dim, output_dim)\n",
    "        self.decoder = DotProductDecoder()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        z = self.encoder(x, edge_index)\n",
    "        adj_pred = self.decoder(z)\n",
    "        return adj_pred, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from random import randint\n",
    "from sys import float_info\n",
    "\n",
    "instances = {}\n",
    "for k in range(0, 1000):\n",
    "    nodes = {}\n",
    "    for i in range(0, 50):\n",
    "        lat_i = randint(0, 100)\n",
    "        lon_i = randint(0, 100)\n",
    "        node_i = (lat_i, lon_i)\n",
    "        lat_j = randint(0, 100)\n",
    "        lon_j = randint(0, 100)\n",
    "        node_j = (lat_j, lon_j)\n",
    "        nodes[i + 1] = node_i\n",
    "        nodes[i + 51] = node_j\n",
    "\n",
    "    dist = {}\n",
    "    pairs = {}\n",
    "    for i in range(1, 101):\n",
    "        for j in range(1, 101):\n",
    "            if i != j:\n",
    "                dist[i,j] = sqrt( (nodes[i][0] - nodes[j][0])**2 + (nodes[i][1] - nodes[j][1])**2 )\n",
    "            else:\n",
    "                dist[i,j] = float_info.max\n",
    "    for i in range(1, 101):\n",
    "        for j in range(1, 101):\n",
    "            if i not in pairs:\n",
    "                pairs[i] = j\n",
    "            if i != j:\n",
    "                if dist[i,j] < dist[i,pairs[i]]:\n",
    "                    pairs[i] = j\n",
    "\n",
    "    nodes[0] = (0,0)\n",
    "    for i in range(1,101):\n",
    "        dist[0,i] = sqrt( (nodes[0][0] - nodes[i][0])**2 + (nodes[0][1] - nodes[i][1])**2 )\n",
    "        dist[i,0] = dist[0,i]\n",
    "    y = [[0 for _ in range(101)] for _ in range(101)]\n",
    "    for i in range(101):\n",
    "        if i > 0:\n",
    "            y[i][pairs[i]] = 1\n",
    "                \n",
    "    instances[k] = {\"nodes\": nodes, \"dist\": dist, \"y\": y}\n",
    "\n",
    "from torch_geometric.nn import knn_graph\n",
    "data_list = []\n",
    "for instance_name in instances:\n",
    "    y = torch.tensor(instances[instance_name][\"y\"], dtype=torch.float)\n",
    "    x = torch.tensor([instances[instance_name][\"nodes\"][i] for i in range(0, 101)], dtype=torch.float)\n",
    "    pos = []\n",
    "    for i in range(101):\n",
    "        pos.append(instances[instance_name][\"nodes\"][i])\n",
    "    pos = torch.tensor(pos, dtype=torch.double)\n",
    "    # ## filtering by TW, strict\n",
    "    # complete_graph_list = []\n",
    "    # for i in range(101):\n",
    "    #     for j in range(101):\n",
    "    #         if i!=j:\n",
    "    #             try:\n",
    "    #                 if instance_dict[instance_name][i][5] + instance_dict[instance_name][i][6] + loc_dict[i][j] < instance_dict[instance_name][i][5]:\n",
    "    #                     complete_graph_list.append([i,j])\n",
    "    #             except:\n",
    "    #                 continue\n",
    "    # edge_index = torch.tensor(complete_graph_list, dtype=torch.double).t().contiguous()\n",
    "    ## end filtering\n",
    "    data_list.append(Data(x=x, y=y, edge_index = knn_graph(x, 15), pos=pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[101, 2], edge_index=[2, 1308], y=[101, 101], pos=[101, 2], edge_label=[654], edge_label_index=[2, 654]),\n",
       " Data(x=[101, 2], edge_index=[2, 1308], y=[101, 101], pos=[101, 2], edge_label=[76], edge_label_index=[2, 76]),\n",
       " Data(x=[101, 2], edge_index=[2, 1384], y=[101, 101], pos=[101, 2], edge_label=[152], edge_label_index=[2, 152]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_graphs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Batch\n",
    "\n",
    "def custom_collate(data_list):\n",
    "    batch = Batch.from_data_list(data_list)\n",
    "\n",
    "    # Manually handle edge_label and edge_label_index if they exist in the data_list\n",
    "    if hasattr(data_list[0], 'edge_label_index'):\n",
    "        edge_label_index_list = [data.edge_label_index for data in data_list]\n",
    "        batch.edge_label_index = torch.cat(edge_label_index_list, dim=1)\n",
    "        \n",
    "    if hasattr(data_list[0], 'edge_label'):\n",
    "        edge_label_list = [data.edge_label for data in data_list]\n",
    "        batch.edge_label = torch.cat(edge_label_list, dim=0)\n",
    "        \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = [g[0] for g in labeled_graphs]\n",
    "val_size = [g[1] for g in labeled_graphs]\n",
    "test_size = [g[2] for g in labeled_graphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_size, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_size, batch_size=20, shuffle=False)\n",
    "test_loader = DataLoader(test_size, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[2020, 2], edge_index=[2, 25794], y=[2020, 101], pos=[2020, 2], edge_label=[12897], edge_label_index=[2, 12897], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25712], y=[2020, 101], pos=[2020, 2], edge_label=[12856], edge_label_index=[2, 12856], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25696], y=[2020, 101], pos=[2020, 2], edge_label=[12848], edge_label_index=[2, 12848], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25478], y=[2020, 101], pos=[2020, 2], edge_label=[12739], edge_label_index=[2, 12739], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25672], y=[2020, 101], pos=[2020, 2], edge_label=[12836], edge_label_index=[2, 12836], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25806], y=[2020, 101], pos=[2020, 2], edge_label=[12903], edge_label_index=[2, 12903], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25796], y=[2020, 101], pos=[2020, 2], edge_label=[12898], edge_label_index=[2, 12898], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25560], y=[2020, 101], pos=[2020, 2], edge_label=[12780], edge_label_index=[2, 12780], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25612], y=[2020, 101], pos=[2020, 2], edge_label=[12806], edge_label_index=[2, 12806], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25812], y=[2020, 101], pos=[2020, 2], edge_label=[12906], edge_label_index=[2, 12906], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25406], y=[2020, 101], pos=[2020, 2], edge_label=[12703], edge_label_index=[2, 12703], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25576], y=[2020, 101], pos=[2020, 2], edge_label=[12788], edge_label_index=[2, 12788], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25662], y=[2020, 101], pos=[2020, 2], edge_label=[12831], edge_label_index=[2, 12831], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25690], y=[2020, 101], pos=[2020, 2], edge_label=[12845], edge_label_index=[2, 12845], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25770], y=[2020, 101], pos=[2020, 2], edge_label=[12885], edge_label_index=[2, 12885], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25606], y=[2020, 101], pos=[2020, 2], edge_label=[12803], edge_label_index=[2, 12803], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25832], y=[2020, 101], pos=[2020, 2], edge_label=[12916], edge_label_index=[2, 12916], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25636], y=[2020, 101], pos=[2020, 2], edge_label=[12818], edge_label_index=[2, 12818], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25598], y=[2020, 101], pos=[2020, 2], edge_label=[12799], edge_label_index=[2, 12799], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25778], y=[2020, 101], pos=[2020, 2], edge_label=[12889], edge_label_index=[2, 12889], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25776], y=[2020, 101], pos=[2020, 2], edge_label=[12888], edge_label_index=[2, 12888], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25778], y=[2020, 101], pos=[2020, 2], edge_label=[12889], edge_label_index=[2, 12889], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25696], y=[2020, 101], pos=[2020, 2], edge_label=[12848], edge_label_index=[2, 12848], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25710], y=[2020, 101], pos=[2020, 2], edge_label=[12855], edge_label_index=[2, 12855], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25666], y=[2020, 101], pos=[2020, 2], edge_label=[12833], edge_label_index=[2, 12833], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25650], y=[2020, 101], pos=[2020, 2], edge_label=[12825], edge_label_index=[2, 12825], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25354], y=[2020, 101], pos=[2020, 2], edge_label=[12677], edge_label_index=[2, 12677], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25694], y=[2020, 101], pos=[2020, 2], edge_label=[12847], edge_label_index=[2, 12847], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25534], y=[2020, 101], pos=[2020, 2], edge_label=[12767], edge_label_index=[2, 12767], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25762], y=[2020, 101], pos=[2020, 2], edge_label=[12881], edge_label_index=[2, 12881], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25622], y=[2020, 101], pos=[2020, 2], edge_label=[12811], edge_label_index=[2, 12811], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25710], y=[2020, 101], pos=[2020, 2], edge_label=[12855], edge_label_index=[2, 12855], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25718], y=[2020, 101], pos=[2020, 2], edge_label=[12859], edge_label_index=[2, 12859], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25872], y=[2020, 101], pos=[2020, 2], edge_label=[12936], edge_label_index=[2, 12936], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25568], y=[2020, 101], pos=[2020, 2], edge_label=[12784], edge_label_index=[2, 12784], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25746], y=[2020, 101], pos=[2020, 2], edge_label=[12873], edge_label_index=[2, 12873], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25646], y=[2020, 101], pos=[2020, 2], edge_label=[12823], edge_label_index=[2, 12823], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25514], y=[2020, 101], pos=[2020, 2], edge_label=[12757], edge_label_index=[2, 12757], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25714], y=[2020, 101], pos=[2020, 2], edge_label=[12857], edge_label_index=[2, 12857], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25400], y=[2020, 101], pos=[2020, 2], edge_label=[12700], edge_label_index=[2, 12700], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25536], y=[2020, 101], pos=[2020, 2], edge_label=[12768], edge_label_index=[2, 12768], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25752], y=[2020, 101], pos=[2020, 2], edge_label=[12876], edge_label_index=[2, 12876], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25634], y=[2020, 101], pos=[2020, 2], edge_label=[12817], edge_label_index=[2, 12817], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25528], y=[2020, 101], pos=[2020, 2], edge_label=[12764], edge_label_index=[2, 12764], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25554], y=[2020, 101], pos=[2020, 2], edge_label=[12777], edge_label_index=[2, 12777], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25418], y=[2020, 101], pos=[2020, 2], edge_label=[12709], edge_label_index=[2, 12709], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25726], y=[2020, 101], pos=[2020, 2], edge_label=[12863], edge_label_index=[2, 12863], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25758], y=[2020, 101], pos=[2020, 2], edge_label=[12879], edge_label_index=[2, 12879], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25662], y=[2020, 101], pos=[2020, 2], edge_label=[12831], edge_label_index=[2, 12831], batch=[2020], ptr=[21])\n",
      "DataBatch(x=[2020, 2], edge_index=[2, 25616], y=[2020, 101], pos=[2020, 2], edge_label=[12808], edge_label_index=[2, 12808], batch=[2020], ptr=[21])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.9940592956542968\n",
      "Epoch 1, Loss: 1.9940592956542968\n",
      "Epoch 2, Loss: 1.9940592956542968\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m adj_dense \u001b[38;5;241m=\u001b[39m adj_dense\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m adj_pred, _ \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index)\n\u001b[1;32m---> 22\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_pred\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_dense\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\jotape\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jotape\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jotape\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jotape\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\functional.py:3154\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3151\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3152\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "# Assume `data_list` contains multiple graphs with `x`, `edge_index` attributes.\n",
    "# data_list = [...] \n",
    "\n",
    "input_dim = 2\n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "model = GraphAutoencoder(input_dim, hidden_dim, output_dim)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        # optimizer.zero_grad()\n",
    "        adj_dense = to_dense_adj(data.edge_index, max_num_nodes=data.num_nodes)[0]\n",
    "        adj_dense = adj_dense.view(-1)\n",
    "        adj_pred, _ = model(data.x, data.edge_index)\n",
    "        loss = criterion(adj_pred.view(-1), adj_dense)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch {epoch}, Loss: {total_loss / len(data_list)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
