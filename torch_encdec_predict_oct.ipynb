{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ng learning with capacities</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the last results and also taking into consideration that TW and Capacity play a role in the difficulty to solve a CVRPTW problem, this latter should also be considered in the learning stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import knn_graph\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import copy\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Get graphs</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_files_list = [\"./export/\"+f for f in os.listdir(\"./export\") ]\n",
    "instance_dict = {}\n",
    "instance_additionals = {}\n",
    "set_sizes_dict = {}\n",
    "for dir_str in data_files_list:\n",
    "    with open(dir_str, 'r') as text_file:\n",
    "        cnt = 0\n",
    "        instance = \"\"\n",
    "        for line in text_file:\n",
    "            if cnt < 9:\n",
    "                if cnt == 0:\n",
    "                    instance = line.split()[0]\n",
    "                    instance_dict[instance] = []\n",
    "                if cnt == 4:\n",
    "                    instance_additionals[instance] = []\n",
    "                    split_line = line.split()\n",
    "                    instance_additionals[instance].append([int(i) for i in split_line])\n",
    "                cnt += 1\n",
    "                continue\n",
    "            split_line = line.split()\n",
    "            instance_dict[instance].append([int(i) for i in split_line])\n",
    "        text_file.close()\n",
    "\n",
    "ng_dict = {}\n",
    "cnt = -1\n",
    "with open(\"ng_outs.csv\", 'r') as text_file:\n",
    "    for line in text_file:\n",
    "        if cnt < 2:\n",
    "            cnt += 1\n",
    "            continue\n",
    "        raw_line = line.strip()\n",
    "        split_line_list = raw_line.split(sep=\";\")\n",
    "        instance = split_line_list[3]\n",
    "        if instance not in ng_dict:\n",
    "            ng_dict[instance] = [[0 for i in range(101)]]\n",
    "        ng_dict[instance].append([0] + [int(i) for i in split_line_list[5:-1]])\n",
    "        set_sizes_dict[instance] = sum(sum(i) for i in ng_dict[instance])\n",
    "        if len(split_line_list[5:-1]) != 100:\n",
    "            print(\"case found for instance \"+instance)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Select appropriate graphs considering difficulty</h3>\n",
    "Here's a sensitive topic, because the definition of difficulty can be considered by computation, then using Uchoa et al. 2016 should be enough, but also we need small and big Ng-Sets, sample from data distributions and so on. The plan will be then to sample from the easy ones and take all of the difficult ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_difficulty = [(k,v) for k,v in set_sizes_dict.items()]\n",
    "ordered_difficulty = sorted(ordered_difficulty, key=lambda tup: tup[1], reverse=True)\n",
    "instances_to_add = [ordered_difficulty[i][0] for i in range(0,1000)]\n",
    "instances_remaining = [ordered_difficulty[i][0] for i in range(1000,len(ordered_difficulty))]\n",
    "easy_instances = sample(instances_remaining, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare graphs for Encoding-Decoding routine</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "aux_data_list = []\n",
    "\n",
    "\n",
    "for instance_name in ng_dict:\n",
    "    instance = instance_dict[instance_name]\n",
    "    y = torch.tensor(ng_dict[instance_name], dtype=torch.float)\n",
    "    x = torch.tensor(instance, dtype=torch.float)\n",
    "    pos = []\n",
    "    tw_sets_dict = {}\n",
    "    for i in instance:\n",
    "        pos.append([i[1], i[2]])\n",
    "    pos = torch.tensor(pos, dtype=torch.double)\n",
    "    edge_index = knn_graph(pos, 15)\n",
    "    data_list.append(Data(x=x, y=y, edge_index=edge_index, pos=pos))\n",
    "    aux_data_list.append(instance_additionals[instance_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge_labels(graph):\n",
    "    transform = T.RandomLinkSplit(num_val=0.05, num_test=0.1, is_undirected=True,\n",
    "                      add_negative_train_samples=False)\n",
    "    return transform(graph)\n",
    "\n",
    "labeled_graphs = [add_edge_labels(graph) for graph in data_list]\n",
    "shuffle(labeled_graphs)\n",
    "\n",
    "train_size = [g[0] for g in labeled_graphs]\n",
    "val_size = [g[1] for g in labeled_graphs]\n",
    "test_size = [g[2] for g in labeled_graphs]\n",
    "\n",
    "train_loader = DataLoader(train_size, batch_size=150, shuffle=True)\n",
    "val_loader = DataLoader(val_size, batch_size=150, shuffle=False)\n",
    "test_loader = DataLoader(test_size, batch_size=150, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Encoding-Decoding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        # self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        # x = self.conv2(x, edge_index).relu()\n",
    "        # x = self.conv3(x, edge_index).relu()\n",
    "        return self.conv4(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ed = Net(data_list[0].num_features, 64, 32).to(device)\n",
    "optimizer = torch.optim.Adam(params=model_ed.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader, epoch):\n",
    "    model_ed.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    if epoch == 8:\n",
    "        for g in optimizer.param_groups:\n",
    "            g['lr'] = 0.001\n",
    "\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        z = model_ed.encode(batch.x, batch.edge_index)\n",
    "\n",
    "        # We perform a new round of negative sampling for every training epoch:\n",
    "        neg_edge_index = negative_sampling(\n",
    "            edge_index=batch.edge_index, num_nodes=batch.num_nodes,\n",
    "            num_neg_samples=batch.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "        # Concat positive and negative edge indices.\n",
    "        edge_label_index = torch.cat(\n",
    "            [batch.edge_label_index, neg_edge_index],\n",
    "            dim=-1,\n",
    "        )\n",
    "        # Label for positive edges: 1, for negative edges: 0.\n",
    "        edge_label = torch.cat([\n",
    "            batch.edge_label,\n",
    "            batch.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "        ], dim=0)\n",
    "\n",
    "        # Note: The model is trained in a supervised manner using the given\n",
    "        # `edge_label_index` and `edge_label` targets.\n",
    "        out = model_ed.decode(z, edge_label_index).view(-1)\n",
    "        loss = criterion(out, edge_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader):\n",
    "    model_ed.eval()\n",
    "    all_out = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in loader:\n",
    "        z = model_ed.encode(batch.x, batch.edge_index)\n",
    "        out = model_ed.decode(z, batch.edge_label_index).view(-1).sigmoid()\n",
    "        all_out.append(out.cpu().numpy())\n",
    "        all_labels.append(batch.edge_label.cpu().numpy())\n",
    "\n",
    "    all_out = np.concatenate(all_out)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    return roc_auc_score(all_labels, all_out), [all_labels], [all_out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test Loop\n",
    "best_val_auc = final_test_auc = 0\n",
    "loss_collection = []\n",
    "val_auc_collection = []\n",
    "last_epoch = 30\n",
    "for epoch in range(1, last_epoch + 1):\n",
    "    if epoch > 5:\n",
    "        rate_of_change_in_loss_e = [loss_collection[-i]-loss_collection[-i-1] for i in range(1,3)]\n",
    "        rate_of_change_in_val_e = [val_auc_collection[-i]-val_auc_collection[-i-1] for i in range(1,3)]\n",
    "        rate_of_change_in_loss = sum(rate_of_change_in_loss_e)/len(rate_of_change_in_loss_e)\n",
    "        rate_of_change_in_val = sum(rate_of_change_in_val_e)/len(rate_of_change_in_val_e)\n",
    "        if rate_of_change_in_loss * -1 > 0:\n",
    "            if rate_of_change_in_val * -1 > 0:\n",
    "                y_true = all_labels[0]\n",
    "                y_pred = all_out[0]\n",
    "\n",
    "                fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "                roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "                plt.figure(1)\n",
    "                plt.plot([0, 1], [0, 1], 'k-')\n",
    "                plt.plot(fpr, tpr, label='CNN(area = {:.3f})'.format(roc_auc))\n",
    "                plt.xlabel('False positive rate')\n",
    "                plt.ylabel('True positive rate')\n",
    "                plt.title('ROC curve GCN network\\n2 layers, Hidden width: 256, Output: 64')\n",
    "                plt.legend(loc='best')\n",
    "                plt.show()\n",
    "                break\n",
    "    loss = train(train_loader, epoch)\n",
    "    val_auc, _, _ = test(val_loader)\n",
    "    test_auc, all_labels, all_out = test(test_loader)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "    loss_collection.append(loss)\n",
    "    val_auc_collection.append(val_auc)\n",
    "    if epoch == last_epoch:\n",
    "        y_true = all_labels[0]\n",
    "        y_pred = all_out[0]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "\n",
    "        plt.figure(1)\n",
    "        plt.plot([0, 1], [0, 1], 'k-')\n",
    "        plt.plot(fpr, tpr, label='CNN(area = {:.3f})'.format(roc_auc))\n",
    "        plt.xlabel('False positive rate')\n",
    "        plt.ylabel('True positive rate')\n",
    "        plt.title('ROC curve GCN network\\n2 layers, Hidden width: 256, Output: 64')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Validate encoding</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prepare data for clasification task</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "indices = [i for i in range(len(data_list))]\n",
    "\n",
    "encodings_dict = {}\n",
    "targets_dict = {\"positives\": [], \"negatives\": []}\n",
    "\n",
    "\n",
    "max_count = 19000\n",
    "cnt = 0\n",
    "\n",
    "f = IntProgress(min=0, max=max_count) # instantiate the bar\n",
    "display(f) # display the bar\n",
    "for graph_idx in sample(indices, max_count):\n",
    "    graph = data_list[graph_idx]\n",
    "    ng_matrix = graph.y.tolist()\n",
    "    graph_x = graph.x\n",
    "    encoding_matrix = model_ed.encode(graph_x, graph.edge_index).tolist()\n",
    "    graph_x = graph_x.tolist()\n",
    "    for i in range(1,101):\n",
    "        encode_i = encoding_matrix[i]\n",
    "        node_i = graph_x[i]\n",
    "        new_entry = encode_i + node_i\n",
    "        new_entry = [\"%.5f\" % e for e in new_entry]\n",
    "        new_entry = [float(e) for e in new_entry]\n",
    "        encodings_dict[graph_idx, i] = new_entry\n",
    "        for j in range(1,101):\n",
    "            if i != j:\n",
    "                target = int(ng_matrix[i][j])\n",
    "                if target == 1:\n",
    "                    targets_dict[\"positives\"].append((graph_idx, i, j))\n",
    "                else:\n",
    "                    targets_dict[\"negatives\"].append((graph_idx, i, j))\n",
    "    f.value += 1\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_candidates = sample(targets_dict[\"positives\"], 200000)\n",
    "neg_candidates = sample(targets_dict[\"negatives\"], 200000)\n",
    "pos_list = [aux_data_list[k[0]][0] + encodings_dict[k[0], k[1]] + encodings_dict[k[0], k[2]] + [1] for k in pos_candidates]\n",
    "neg_list = [aux_data_list[k[0]][0] + encodings_dict[k[0], k[1]] + encodings_dict[k[0], k[2]] + [0] for k in neg_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_tensor = pos_list + neg_list\n",
    "main_tensor = torch.tensor(pre_tensor, dtype=torch.float32)\n",
    "\n",
    "main_tensor = main_tensor[torch.randperm(main_tensor.size()[0])]\n",
    "labels = main_tensor[:,-1:]\n",
    "embeddings = main_tensor[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Classification model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deep4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(80, 80) #142\n",
    "        self.act1 = nn.ReLU()\n",
    "        # self.layer1_1 = nn.Linear(284, 142)\n",
    "        # self.act1_1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(80, 40)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(40, 40)\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.output = nn.Linear(40, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.layer1(x))\n",
    "        # x = self.act1_1(self.layer1_1(x))\n",
    "        x = self.act2(self.layer2(x))\n",
    "        x = self.act3(self.layer3(x))\n",
    "        x = self.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model, X_train, y_train, X_val, y_val):\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.BCELoss()  # binary cross entropy\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    " \n",
    "    n_epochs = 60   # number of epochs to run\n",
    "    batch_size = 500  # size of each batch\n",
    "    batch_start = torch.arange(0, len(X_train), batch_size)\n",
    " \n",
    "    # Hold the best model\n",
    "    best_acc = - np.inf   # init to negative infinity\n",
    "    best_weights = None\n",
    "\n",
    "    loss_collection = []\n",
    "    val_auc_collection = []\n",
    " \n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        if epoch > 5:\n",
    "            rate_of_change_in_loss_e = [loss_collection[-i]-loss_collection[-i-1] for i in range(1,3)]\n",
    "            rate_of_change_in_val_e = [val_auc_collection[-i]-val_auc_collection[-i-1] for i in range(1,3)]\n",
    "            rate_of_change_in_loss = sum(rate_of_change_in_loss_e)/len(rate_of_change_in_loss_e)\n",
    "            rate_of_change_in_val = sum(rate_of_change_in_val_e)/len(rate_of_change_in_val_e)\n",
    "            if rate_of_change_in_loss * -1 > 0:\n",
    "                if rate_of_change_in_val * -1 > 0:\n",
    "                    y_true = y_val\n",
    "                    y_pred = y_pred\n",
    "\n",
    "                    fpr, tpr, _ = roc_curve(y_true, y_pred.detach().numpy())\n",
    "                    roc_auc = roc_auc_score(y_true, y_pred.detach().numpy())\n",
    "\n",
    "                    plt.figure(1)\n",
    "                    plt.plot([0, 1], [0, 1], 'k-')\n",
    "                    plt.plot(fpr, tpr, label='CNN(area = {:.3f})'.format(roc_auc))\n",
    "                    plt.xlabel('False positive rate')\n",
    "                    plt.ylabel('True positive rate')\n",
    "                    plt.title('ROC curve Classification network\\n3 layers, Hidden width: 40, Output: 1')\n",
    "                    plt.legend(loc='best')\n",
    "                    plt.show()\n",
    "                    break\n",
    "        if epoch == 30:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] = 0.0001\n",
    "        model.train()\n",
    "        with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=True) as bar:\n",
    "            bar.set_description(f\"Epoch {epoch}\")\n",
    "            for start in bar:\n",
    "                # take a batch\n",
    "                X_batch = X_train[start:start+batch_size]\n",
    "                y_batch = y_train[start:start+batch_size]\n",
    "                # forward pass\n",
    "                y_pred = model(X_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                # backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                # update weights\n",
    "                optimizer.step()\n",
    "                # print progress\n",
    "                acc = (y_pred.round() == y_batch).float().mean()\n",
    "                bar.set_postfix(\n",
    "                    loss=float(loss),\n",
    "                    acc=float(acc)\n",
    "                )\n",
    "        # evaluate accuracy at end of each epoch\n",
    "        model.eval()\n",
    "        y_pred = model(X_val)\n",
    "        acc = (y_pred.round() == y_val).float().mean()\n",
    "        acc = float(acc)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "        loss_collection.append(loss)\n",
    "        val_auc_collection.append(roc_auc_score(y_val, y_pred.detach().numpy()))\n",
    "        if epoch == n_epochs:\n",
    "            y_true = y_val\n",
    "            y_pred = y_pred\n",
    "\n",
    "            fpr, tpr, _ = roc_curve(y_true, y_pred.detach().numpy())\n",
    "            roc_auc = roc_auc_score(y_true, y_pred.detach().numpy())\n",
    "\n",
    "            plt.figure(1)\n",
    "            plt.plot([0, 1], [0, 1], 'k-')\n",
    "            plt.plot(fpr, tpr, label='CNN(area = {:.3f})'.format(roc_auc))\n",
    "            plt.xlabel('False positive rate')\n",
    "            plt.ylabel('True positive rate')\n",
    "            plt.title('ROC curve Classification network\\n3 layers, Hidden width: 40, Output: 1')\n",
    "            plt.legend(loc='best')\n",
    "            plt.show()\n",
    "    # restore model and return best accuracy\n",
    "    model.load_state_dict(best_weights)\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ls = Deep4()\n",
    "acc = model_train(model_ls, X_train, y_train, X_test, y_test)\n",
    "print(f\"Final model accuracy: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Validate classification</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
