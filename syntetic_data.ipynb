{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from random import randint\n",
    "from sys import float_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = {}\n",
    "for k in range(0, 5000):\n",
    "    nodes = {}\n",
    "    for i in range(0, 50):\n",
    "        lat_i = randint(0, 100)\n",
    "        lon_i = randint(0, 100)\n",
    "        node_i = (lat_i, lon_i)\n",
    "        lat_j = randint(0, 100)\n",
    "        lon_j = randint(0, 100)\n",
    "        node_j = (lat_j, lon_j)\n",
    "        nodes[i + 1] = node_i\n",
    "        nodes[i + 51] = node_j\n",
    "\n",
    "    dist = {}\n",
    "    pairs = {}\n",
    "    for i in range(1, 101):\n",
    "        for j in range(1, 101):\n",
    "            if i != j:\n",
    "                dist[i,j] = sqrt( (nodes[i][0] - nodes[j][0])**2 + (nodes[i][1] - nodes[j][1])**2 )\n",
    "            else:\n",
    "                dist[i,j] = float_info.max\n",
    "    for i in range(1, 101):\n",
    "        for j in range(1, 101):\n",
    "            if i not in pairs:\n",
    "                pairs[i] = j\n",
    "            if i != j:\n",
    "                if dist[i,j] < dist[i,pairs[i]]:\n",
    "                    pairs[i] = j\n",
    "\n",
    "    nodes[0] = (0,0)\n",
    "    for i in range(1,101):\n",
    "        dist[0,i] = sqrt( (nodes[0][0] - nodes[i][0])**2 + (nodes[0][1] - nodes[i][1])**2 )\n",
    "        dist[i,0] = dist[0,i]\n",
    "    y = [[0 for _ in range(101)] for _ in range(101)]\n",
    "    for i in range(101):\n",
    "        for j in range(101):\n",
    "            if i > 0:\n",
    "                if dist[0,i] < dist[0,pairs[i]]:\n",
    "                    y[pairs[i]][i] = 1\n",
    "                else:\n",
    "                    y[i][pairs[i]] = 1\n",
    "                \n",
    "    instances[k] = {\"nodes\": nodes, \"dist\": dist, \"y\": y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_graph_list = []\n",
    "for i in range(101):\n",
    "    for j in range(101):\n",
    "        if i != j:\n",
    "            complete_graph_list.append([i,j])\n",
    "edge_index = torch.tensor(complete_graph_list, dtype=torch.double).t().contiguous()\n",
    "n_edges = len(complete_graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for instance_name in instances:\n",
    "    y = torch.tensor(instances[instance_name][\"y\"], dtype=torch.double)\n",
    "    x = torch.tensor([instances[instance_name][\"nodes\"][i] for i in range(0, 101)], dtype=torch.double)\n",
    "    attr = [[i] for i in range(n_edges)]\n",
    "    cnt = -1\n",
    "    for i in range(101):\n",
    "        for j in range(101):\n",
    "            if i != j:\n",
    "                cnt += 1\n",
    "                attr[cnt].append(instances[instance_name][\"dist\"][i,j])\n",
    "    attr = torch.tensor(attr, dtype=torch.double)\n",
    "    pos = []\n",
    "    for i in range(101):\n",
    "        pos.append(instances[instance_name][\"nodes\"][i])\n",
    "    pos = torch.tensor(pos, dtype=torch.double)\n",
    "    # ## filtering by TW, strict\n",
    "    # complete_graph_list = []\n",
    "    # for i in range(101):\n",
    "    #     for j in range(101):\n",
    "    #         if i!=j:\n",
    "    #             try:\n",
    "    #                 if instance_dict[instance_name][i][5] + instance_dict[instance_name][i][6] + loc_dict[i][j] < instance_dict[instance_name][i][5]:\n",
    "    #                     complete_graph_list.append([i,j])\n",
    "    #             except:\n",
    "    #                 continue\n",
    "    # edge_index = torch.tensor(complete_graph_list, dtype=torch.double).t().contiguous()\n",
    "    ## end filtering\n",
    "    data_list.append(Data(x=x, y=y, edge_index=edge_index, pos=pos, edge_attr=attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_source = Instances(data_list)\n",
    "dataloader = DataLoader(data_list[0:1468], batch_size=1)\n",
    "data_test = DataLoader(data_list[1468:1488], batch_size=1)\n",
    "# datatorch = data_source.to_conv_nets(start=428, end=1458, batch_size=10)\n",
    "# torchtest = data_source.to_conv_nets(start=1458, end=488, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Sequential as Seq, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing\n",
    "\n",
    "class EdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='max') #  \"Max\" aggregation.\n",
    "        self.mlp = Seq(Linear(2 * in_channels, out_channels),\n",
    "                       ReLU(),\n",
    "                       Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        # x_i has shape [E, in_channels]\n",
    "        # x_j has shape [E, in_channels]\n",
    "\n",
    "        tmp = torch.cat([x_i, x_j - x_i], dim=1)  # tmp has shape [E, 2 * in_channels]\n",
    "        return self.mlp(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import knn_graph\n",
    "\n",
    "class DynamicEdgeConv(EdgeConv):\n",
    "    def __init__(self, in_channels, out_channels, k=6):\n",
    "        super().__init__(in_channels, out_channels)\n",
    "        self.k = k\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x, batch=None):\n",
    "        edge_index = knn_graph(x, self.k, batch, loop=False, flow=self.flow)\n",
    "        return super().forward(x, edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCustomLoss(my_outputs, objective_matrix):\n",
    "    #specifying the batch size\n",
    "    my_batch_size = my_outputs.size()[0]\n",
    "    #selecting the values that correspond to labels\n",
    "    diff = torch.abs(my_outputs - objective_matrix)\n",
    "    return torch.sum(diff*diff)/(101*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    if epoch == 51:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.5 * param_group['lr']\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in dataloader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # print(data.x, data.edge_index, data.batch)\n",
    "        output = model(data.x)\n",
    "        # print(output, data.y)\n",
    "        # print(output)\n",
    "        loss = myCustomLoss(output, data.y)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item() * data.num_graphs\n",
    "        optimizer.step()\n",
    "        test_size = 101*100*1 #extract batch size\n",
    "    return loss_all / test_size\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        output = model(data.x)\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        test_size = 101*100*1 #extract batch size\n",
    "    return correct / test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.0919, Train Acc: 0.1998, Test Acc: 0.0003\n",
      "Epoch: 002, Loss: 0.0014, Train Acc: 1.5092, Test Acc: 0.0100\n",
      "Epoch: 003, Loss: 0.0013, Train Acc: 2.3975, Test Acc: 0.0498\n",
      "Epoch: 004, Loss: 0.0013, Train Acc: 0.2928, Test Acc: 0.0099\n",
      "Epoch: 005, Loss: 0.0013, Train Acc: 0.1654, Test Acc: 0.0001\n",
      "Epoch: 006, Loss: 0.0013, Train Acc: 0.0035, Test Acc: 0.0001\n",
      "Epoch: 007, Loss: 0.0013, Train Acc: 0.0002, Test Acc: 0.0000\n",
      "Epoch: 008, Loss: 0.0013, Train Acc: 0.0099, Test Acc: 0.0000\n",
      "Epoch: 009, Loss: 0.0013, Train Acc: 0.0099, Test Acc: 0.0000\n",
      "Epoch: 010, Loss: 0.0013, Train Acc: 0.0099, Test Acc: 0.0000\n",
      "Epoch: 011, Loss: 0.0013, Train Acc: 0.0016, Test Acc: 0.0000\n",
      "Epoch: 012, Loss: 0.0012, Train Acc: 0.0003, Test Acc: 0.0000\n",
      "Epoch: 013, Loss: 0.0012, Train Acc: 0.0012, Test Acc: 0.0000\n",
      "Epoch: 014, Loss: 0.0012, Train Acc: 0.0004, Test Acc: 0.0000\n",
      "Epoch: 015, Loss: 0.0012, Train Acc: 0.0009, Test Acc: 0.0000\n",
      "Epoch: 016, Loss: 0.0012, Train Acc: 0.0025, Test Acc: 0.0001\n",
      "Epoch: 017, Loss: 0.0012, Train Acc: 0.0016, Test Acc: 0.0001\n",
      "Epoch: 018, Loss: 0.0012, Train Acc: 0.0032, Test Acc: 0.0000\n",
      "Epoch: 019, Loss: 0.0012, Train Acc: 0.9340, Test Acc: 0.0298\n",
      "Epoch: 020, Loss: 0.0011, Train Acc: 10.7204, Test Acc: 0.1584\n",
      "Epoch: 021, Loss: 0.0011, Train Acc: 3.9081, Test Acc: 0.0526\n",
      "Epoch: 022, Loss: 0.0011, Train Acc: 5.2674, Test Acc: 0.0715\n",
      "Epoch: 023, Loss: 0.0011, Train Acc: 2.2653, Test Acc: 0.0395\n",
      "Epoch: 024, Loss: 0.0011, Train Acc: 0.0237, Test Acc: 0.0003\n",
      "Epoch: 025, Loss: 0.0011, Train Acc: 0.0022, Test Acc: 0.0000\n",
      "Epoch: 026, Loss: 0.0011, Train Acc: 0.2682, Test Acc: 0.0000\n",
      "Epoch: 027, Loss: 0.0011, Train Acc: 0.0000, Test Acc: 0.0000\n",
      "Epoch: 028, Loss: 0.0011, Train Acc: 1.0737, Test Acc: 0.0008\n",
      "Epoch: 029, Loss: 0.0010, Train Acc: 0.0830, Test Acc: 0.0001\n",
      "Epoch: 030, Loss: 0.0010, Train Acc: 0.0060, Test Acc: 0.0000\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = DynamicEdgeConv(2, 101).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model_dict = {}\n",
    "\n",
    "for epoch in range(1, 31):\n",
    "    loss = train(epoch)\n",
    "    train_acc = test(dataloader)\n",
    "    test_acc = test(data_test)\n",
    "    model_dict[epoch] = {\"model\": deepcopy(model), \"loss\": loss, \"trainAcc\": train_acc, \"testAcc\": test_acc}\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "          f'Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
