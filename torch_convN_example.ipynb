{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Example of use with PyTorch with Convolutional Network by Bresson & Laurent</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used by Kool et al. (2021) and Joshi et al. (2019) to form routes, using the incidence matrix image as the classes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_files_list = [\"./export/\"+f for f in os.listdir(\"./export\") ]\n",
    "instance_dict = {}\n",
    "for dir_str in data_files_list:\n",
    "    with open(dir_str, 'r') as text_file:\n",
    "        cnt = 0\n",
    "        instance = \"\"\n",
    "        for line in text_file:\n",
    "            if cnt < 9:\n",
    "                if cnt == 0:\n",
    "                    instance = line.split()[0]\n",
    "                    instance_dict[instance] = []\n",
    "                cnt += 1\n",
    "                continue\n",
    "            split_line = line.split()\n",
    "            instance_dict[instance].append([int(i) for i in split_line])\n",
    "        text_file.close()\n",
    "\n",
    "ng_dict = {}\n",
    "cnt = -1\n",
    "with open(\"ng_outs.csv\", 'r') as text_file:\n",
    "    for line in text_file:\n",
    "        if cnt < 2:\n",
    "            cnt += 1\n",
    "            continue\n",
    "        raw_line = line.strip()\n",
    "        split_line_list = raw_line.split(sep=\";\")\n",
    "        instance = split_line_list[3]\n",
    "        if instance not in ng_dict:\n",
    "            ng_dict[instance] = [[0 for i in range(101)]]\n",
    "        ng_dict[instance].append([0] + [int(i) for i in split_line_list[5:-1]])\n",
    "        if len(split_line_list[5:-1]) != 100:\n",
    "            print(\"case found for instance \"+instance)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "import networkx as nx\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GraphConv, global_add_pool\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_graph_list = []\n",
    "for i in range(101):\n",
    "    for j in range(101):\n",
    "        if i != j:\n",
    "            complete_graph_list.append([i,j])\n",
    "edge_index = torch.tensor(complete_graph_list, dtype=torch.long).t().contiguous()\n",
    "n_edges = len(complete_graph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance_name in ng_dict:\n",
    "    for i in range(101):\n",
    "        for j in range(101):\n",
    "            if i == j:\n",
    "                ng_dict[instance_name][i][j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for instance_name in ng_dict:\n",
    "    y = torch.tensor(ng_dict[instance_name], dtype=torch.double)\n",
    "    x = torch.tensor(instance_dict[instance_name], dtype=torch.double)\n",
    "    attr = [[i] for i in range(n_edges)]\n",
    "    loc_dict = {(i[0],j[0]): sqrt((i[1]-j[1])**2 + (i[2]-j[2])**2) for i in instance_dict[instance_name] for j in instance_dict[instance_name]}\n",
    "    cnt = -1\n",
    "    for i in range(101):\n",
    "        for j in range(101):\n",
    "            if i != j:\n",
    "                cnt += 1\n",
    "                attr[cnt].append(loc_dict[i,j])\n",
    "    attr = torch.tensor(attr, dtype=torch.double)\n",
    "    pos = []\n",
    "    for i in instance_dict[instance_name]:\n",
    "        pos.append([i[1], i[2]])\n",
    "    pos = torch.tensor(pos, dtype=torch.double)\n",
    "    data_list.append(Data(x=x, y=y, edge_index=edge_index, pos=pos, edge_attr=attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just to produce edges as an adjacency matrix\n",
    "complete_adj_matrix_list = [[0 for i in range(101)] for i in range(101)]\n",
    "for edge in complete_graph_list:\n",
    "    i, j = edge\n",
    "    complete_adj_matrix_list[i][j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Instances:\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "    \n",
    "    def to_torch_geometric(self, start=0, end=-1, batch_size=1):\n",
    "        return DataLoader(data_list[start:end], batch_size=batch_size)\n",
    "    \n",
    "    def to_conv_nets(self, start=0, end=-1, batch_size=1):\n",
    "        final_data = []\n",
    "        nodes = []\n",
    "        nodes_coor = []\n",
    "        nodes_timew = []\n",
    "        x_edges = []\n",
    "        x_edges_values = []\n",
    "        y_edges = []\n",
    "        cnt = 0\n",
    "        current_batch = 0\n",
    "        for graph in self.data_list[start:end]:\n",
    "            if cnt >= batch_size:\n",
    "                cnt = 0\n",
    "                current_batch += 1\n",
    "                nodes = torch.tensor(nodes, dtype=torch.long)\n",
    "                nodes_coor = torch.tensor(nodes_coor, dtype=torch.float)\n",
    "                nodes_timew = torch.tensor(nodes_timew, dtype=torch.long)\n",
    "                x_edges = torch.tensor(x_edges, dtype=torch.long)\n",
    "                x_edges_values = torch.tensor(x_edges_values, dtype=torch.float)\n",
    "                y_edges = torch.tensor(y_edges, dtype=torch.long)\n",
    "                final_data.append((x_edges, x_edges_values, nodes, nodes_coor, nodes_timew, y_edges))\n",
    "                nodes = []\n",
    "                nodes_coor = []\n",
    "                nodes_timew = []\n",
    "                x_edges = []\n",
    "                x_edges_values = []\n",
    "                y_edges = []\n",
    "            nodes.append([i for i in range(101)]) \n",
    "            nodes_coor.append(graph.pos.tolist())\n",
    "            tw = []\n",
    "            x_raw = graph.x.tolist()\n",
    "            ## filtering by TW, strict\n",
    "            complete_adj_matrix_list = [[0 for i in range(101)] for i in range(101)]\n",
    "            for edge in complete_graph_list:\n",
    "                i, j = edge\n",
    "                if x_raw[i][5] + x_raw[i][6] <  x_raw[j][5]:\n",
    "                    complete_adj_matrix_list[i][j] = 1\n",
    "            ## end filtering\n",
    "            for i in range(101):\n",
    "                tw.append([x_raw[i][4], x_raw[i][5]])\n",
    "            nodes_timew.append(tw)\n",
    "            x_edges.append(complete_adj_matrix_list)\n",
    "            dist_matrix = [[0 for _ in range(101)] for _ in range(101)]\n",
    "            dist_list = [i for _, i in graph.edge_attr.tolist()]\n",
    "            pos_dist = 0\n",
    "            for i in range(101):\n",
    "                for j in range(101):\n",
    "                    if i != j:\n",
    "                        dist_matrix[i][j] = dist_list[pos_dist]\n",
    "                        pos_dist += 1\n",
    "            x_edges_values.append(dist_matrix)\n",
    "            y_edges.append(graph.y.tolist()) #TODO: remove the transpose and also the contiguous when generating y\n",
    "            cnt += 1\n",
    "        return final_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = Instances(data_list)\n",
    "# dataloader = data_source.to_torch_geometric(start=428, end=458, batch_size=1)\n",
    "# data_test = data_source.to_torch_geometric(start=458, end=468, batch_size=1)\n",
    "datatorch = data_source.to_conv_nets(start=428, end=1458, batch_size=1)\n",
    "torchtest = data_source.to_conv_nets(start=1458, end=1468, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormNode(nn.Module):\n",
    "    \"\"\"Batch normalization for node features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(BatchNormNode, self).__init__()\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_dim, track_running_stats=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Node features (batch_size, num_nodes, hidden_dim)\n",
    "\n",
    "        Returns:\n",
    "            x_bn: Node features after batch normalization (batch_size, num_nodes, hidden_dim)\n",
    "        \"\"\"\n",
    "        # The batch norm normalizes the hidden dim over batch and node dimensions\n",
    "        if x.dim() == 2:\n",
    "            # If we have sparse version we have only one batch dimension\n",
    "            # simply perform batch norm over this (so this normalizes over batch and node dimension)\n",
    "            return self.batch_norm(x)\n",
    "        x_trans = x.transpose(1, 2).contiguous()  # Reshape input: (batch_size, hidden_dim, num_nodes)\n",
    "        x_trans_bn = self.batch_norm(x_trans)\n",
    "        x_bn = x_trans_bn.transpose(1, 2).contiguous()  # Reshape to original shape\n",
    "        # x_bn2 = self.batch_norm(x.view(-1, x.size(-1))).view_as(x)\n",
    "        # assert torch.allclose(x_bn, x_bn2, atol=1e-5)\n",
    "        return x_bn\n",
    "\n",
    "\n",
    "class BatchNormEdge(nn.Module):\n",
    "    \"\"\"Batch normalization for edge features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(BatchNormEdge, self).__init__()\n",
    "        self.batch_norm = nn.BatchNorm2d(hidden_dim, track_running_stats=False)\n",
    "\n",
    "    def forward(self, e):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            e: Edge features (batch_size, num_nodes, num_nodes, hidden_dim)\n",
    "\n",
    "        Returns:\n",
    "            e_bn: Edge features after batch normalization (batch_size, num_nodes, num_nodes, hidden_dim)\n",
    "        \"\"\"\n",
    "        # The batch norm normalizes the hidden dim over batch and edge dimensions\n",
    "        if e.dim() == 2:\n",
    "            # If we have sparse version we have only one batch dimension\n",
    "            # simply perform batch norm over this (so this normalizes over batch and node dimension)\n",
    "            # We can use the BatchNorm2d module by inserting dummy dimensions\n",
    "            return self.batch_norm(e[:, :, None, None]).view_as(e)\n",
    "        e_trans = e.transpose(1, 3).contiguous()  # Reshape input: (batch_size, hidden_dim, num_nodes, num_nodes)\n",
    "        e_trans_bn = self.batch_norm(e_trans)\n",
    "        e_bn = e_trans_bn.transpose(1, 3).contiguous()  # Reshape to original\n",
    "        return e_bn\n",
    "\n",
    "class NodeFeatures(nn.Module):\n",
    "    \"\"\"Convnet features for nodes.\n",
    "    \n",
    "    Using `sum` aggregation:\n",
    "        x_i = U*x_i +  sum_j [ gate_ij * (V*x_j) ]\n",
    "    \n",
    "    Using `mean` aggregation:\n",
    "        x_i = U*x_i + ( sum_j [ gate_ij * (V*x_j) ] / sum_j [ gate_ij] )\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim, aggregation=\"mean\"):\n",
    "        super(NodeFeatures, self).__init__() # We must always sum, since mean means 'weighted mean' so sum weighted messages\n",
    "        self.aggregation = aggregation\n",
    "        self.U = nn.Linear(hidden_dim, hidden_dim, True)\n",
    "        self.V = nn.Linear(hidden_dim, hidden_dim, True)\n",
    "\n",
    "    def forward(self, x, edge_gate, edge_index=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Node features (batch_size, num_nodes, hidden_dim)\n",
    "            edge_gate: Edge gate values (batch_size, num_nodes, num_nodes, hidden_dim)\n",
    "\n",
    "        Returns:\n",
    "            x_new: Convolved node features (batch_size, num_nodes, hidden_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        Ux = self.U(x)  # B x V x H\n",
    "        Vx = self.V(x)  # B x V x H\n",
    "\n",
    "        if edge_index is not None:\n",
    "            # Sparse version\n",
    "            return self.propagate(edge_index, Ux=Ux, Vx=Vx, edge_gate=edge_gate)\n",
    "\n",
    "        from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "        # The rest is a relatively cheap operation that uses a lot of memory\n",
    "        # No it does not use a lot of memory\n",
    "        use_checkpoint = False\n",
    "        if use_checkpoint:\n",
    "            x_new = checkpoint(self._inner, edge_gate, Ux, Vx)\n",
    "        else:\n",
    "\n",
    "            x_new = self._inner(edge_gate, Ux, Vx)\n",
    "            # print(\"Dense x\", edge_gate.size(), Ux.size(), Vx.size())\n",
    "            # print(x_new.flatten()[-10:])\n",
    "        return x_new\n",
    "\n",
    "    def _inner(self, edge_gate, Ux, Vx):\n",
    "        use_einsum = False\n",
    "        use_matmul = False\n",
    "\n",
    "        if use_einsum:  # Seems to use more memory\n",
    "            x_add = torch.einsum('bijd,bjd->bid', edge_gate, Vx)\n",
    "        elif use_matmul:  # Seems to use same memory as einsum, not much faster\n",
    "            x_add = torch.matmul(\n",
    "                edge_gate.unsqueeze(1).transpose(1, 4).squeeze(-1),\n",
    "                Vx.unsqueeze(1).transpose(1, 3)\n",
    "            ).transpose(1, 3).squeeze(1)\n",
    "        else:\n",
    "            Vx = Vx.unsqueeze(1)  # extend Vx from \"B x V x H\" to \"B x 1 x V x H\"\n",
    "            gateVx = edge_gate * Vx  # B x V x V x H\n",
    "            x_add = torch.sum(gateVx, dim=-2)\n",
    "        if self.aggregation==\"mean\":\n",
    "            x_new = Ux + x_add / (1e-20 + torch.sum(edge_gate, dim=-2))  # B x V x H\n",
    "        elif self.aggregation==\"sum\":\n",
    "            x_new = Ux + x_add  # B x V x H\n",
    "        return x_new\n",
    "\n",
    "    def message(self, edge_gate, Vx_j):\n",
    "        return edge_gate * Vx_j\n",
    "\n",
    "    def update(self, agg, Ux, edge_gate, edge_index):\n",
    "        src, tgt = edge_index\n",
    "        # Aggregate here exactly as in _inner. Normalizing here is more efficient than normalizing the messages.\n",
    "        if self.aggregation == \"mean\":\n",
    "            gate_sum = scatter(edge_gate, tgt, dim=0, dim_size=Ux.size(0), reduce='sum')\n",
    "            return Ux + agg / (1e-20 + gate_sum)\n",
    "        assert self.aggregation == \"sum\"\n",
    "        return Ux + agg  # Skip connection\n",
    "\n",
    "\n",
    "class EdgeFeatures(nn.Module):\n",
    "    \"\"\"Convnet features for edges.\n",
    "\n",
    "    e_ij = U*e_ij + V*(x_i + x_j)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim, directed=False):\n",
    "        super(EdgeFeatures, self).__init__()\n",
    "        self.U = nn.Linear(hidden_dim, hidden_dim, True)\n",
    "        self.V = nn.Linear(hidden_dim, hidden_dim, True)\n",
    "        self.W = nn.Linear(hidden_dim, hidden_dim, True) if directed else None\n",
    "        \n",
    "    def forward(self, x, e, edge_index=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Node features (batch_size, num_nodes, hidden_dim)\n",
    "            e: Edge features (batch_size, num_nodes, num_nodes, hidden_dim)\n",
    "\n",
    "        Returns:\n",
    "            e_new: Convolved edge features (batch_size, num_nodes, num_nodes, hidden_dim)\n",
    "        \"\"\"\n",
    "        Ue = self.U(e)\n",
    "        Vx = self.V(x)\n",
    "        Wx = Vx if self.W is None else self.W(x)  # If self.W is none, graph is undirected\n",
    "        if edge_index is not None:\n",
    "            # Sparse version\n",
    "            src, dst = edge_index\n",
    "            Wx = Wx[dst]  # = to\n",
    "            Vx = Vx[src]  # = from\n",
    "        else:\n",
    "            Wx = Wx.unsqueeze(1)  # Extend Wx from \"B x V x H\" to \"B x 1 x V x H\" = to\n",
    "            Vx = Vx.unsqueeze(2)  # extend Vx from \"B x V x H\" to \"B x V x 1 x H\" = from\n",
    "\n",
    "        e_new = Ue + Vx + Wx\n",
    "        return e_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualGatedGCNLayer(nn.Module):\n",
    "    \"\"\"Convnet layer with gating and residual connection.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim, aggregation=\"sum\", directed=False):\n",
    "        super(ResidualGatedGCNLayer, self).__init__()\n",
    "        self.node_feat = NodeFeatures(hidden_dim, aggregation)\n",
    "        self.edge_feat = EdgeFeatures(hidden_dim, directed)\n",
    "        self.bn_node = BatchNormNode(hidden_dim)\n",
    "        self.bn_edge = BatchNormEdge(hidden_dim)\n",
    "\n",
    "    def forward(self, x, e, edge_index=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Node features (batch_size, num_nodes, hidden_dim)\n",
    "            e: Edge features (batch_size, num_nodes, num_nodes, hidden_dim)\n",
    "\n",
    "        Returns:\n",
    "            x_new: Convolved node features (batch_size, num_nodes, hidden_dim)\n",
    "            e_new: Convolved edge features (batch_size, num_nodes, num_nodes, hidden_dim)\n",
    "        \"\"\"\n",
    "        e_in = e\n",
    "        x_in = x\n",
    "        # Edge convolution\n",
    "        e_tmp = self.edge_feat(x_in, e_in, edge_index)  # B x V x V x H\n",
    "        # Compute edge gates\n",
    "        edge_gate = F.sigmoid(e_tmp)\n",
    "        # Node convolution\n",
    "        x_tmp = self.node_feat(x_in, edge_gate, edge_index)\n",
    "        # Batch normalization\n",
    "        e_tmp = self.bn_edge(e_tmp)\n",
    "        x_tmp = self.bn_node(x_tmp)\n",
    "        # ReLU Activation\n",
    "        e = F.relu(e_tmp)\n",
    "        x = F.relu(x_tmp)\n",
    "        # Residual connection\n",
    "        x_new = x_in + x\n",
    "        e_new = e_in + e\n",
    "        return x_new, e_new\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Multi-layer Perceptron for output prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim, output_dim, L=2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.L = L\n",
    "        U = []\n",
    "        for layer in range(self.L - 1):\n",
    "            U.append(nn.Linear(hidden_dim, hidden_dim, True))\n",
    "        self.U = nn.ModuleList(U)\n",
    "        self.V = nn.Linear(hidden_dim, output_dim, True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input features (batch_size, hidden_dim)\n",
    "\n",
    "        Returns:\n",
    "            y: Output predictions (batch_size, output_dim)\n",
    "        \"\"\"\n",
    "        Ux = x\n",
    "        for U_i in self.U:\n",
    "            Ux = U_i(Ux)  # B x H\n",
    "            Ux = F.relu(Ux)  # B x H\n",
    "        y = self.V(Ux)  # B x O\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualGatedGCNModelVRP(nn.Module):\n",
    "    \"\"\"Residual Gated GCN Model for outputting predictions as edge adjacency matrices.\n",
    "\n",
    "    References:\n",
    "        Paper: https://arxiv.org/pdf/1711.07553v2.pdf\n",
    "        Code: https://github.com/xbresson/spatial_graph_convnets\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ResidualGatedGCNModelVRP, self).__init__()\n",
    "        self.dtypeFloat = torch.FloatTensor\n",
    "        self.dtypeLong = torch.LongTensor\n",
    "        # Define net parameters\n",
    "        # self.num_nodes = config.num_nodes\n",
    "        # self.node_dim = config.node_dim\n",
    "        # self.voc_nodes_in = config['voc_nodes_in']\n",
    "        # self.voc_nodes_out = config['num_nodes']  # config['voc_nodes_out']\n",
    "        # self.voc_edges_in = config['voc_edges_in']\n",
    "        # self.voc_edges_out = config['voc_edges_out']\n",
    "        # self.hidden_dim = config['hidden_dim']\n",
    "        # self.num_layers = config['num_layers']\n",
    "        # self.mlp_layers = config['mlp_layers']\n",
    "        # self.aggregation = config['aggregation']\n",
    "        # self.num_segments_checkpoint = config.get('num_segments_checkpoint', 0)\n",
    "        self.num_nodes = 100\n",
    "        self.node_dim = 2\n",
    "        self.voc_nodes_in = 101\n",
    "        self.voc_nodes_out = 2\n",
    "        self.voc_edges_in = 3\n",
    "        self.voc_edges_out = 2\n",
    "        self.hidden_dim = 6\n",
    "        self.num_layers = 30\n",
    "        self.mlp_layers = 3\n",
    "        self.aggregation = \"mean\"\n",
    "        self.num_segments_checkpoint = 5\n",
    "\n",
    "        # Node and edge embedding layers/lookups\n",
    "        self.nodes_coord_embedding = nn.Linear(self.node_dim, self.hidden_dim // 2, bias=False)\n",
    "        # self.nodes_coord_embedding2 = nn.Linear(self.node_dim, self.hidden_dim, bias=False)\n",
    "        self.edges_values_embedding = nn.Linear(1, self.hidden_dim // 2, bias=False)\n",
    "        # self.edges_values_embedding2 = nn.Linear(1, self.hidden_dim, bias=False)\n",
    "        self.edges_embedding = nn.Embedding(self.voc_edges_in, self.hidden_dim // 2)\n",
    "        # self.edges_embedding2 = nn.Embedding(self.voc_edges_in, self.hidden_dim)\n",
    "        self.nodes_embedding = nn.Embedding(self.voc_nodes_in, self.hidden_dim // 2)\n",
    "        # self.nodes_embedding2 = nn.Embedding(self.voc_nodes_in, self.hidden_dim)\n",
    "        # Define GCN Layers\n",
    "        gcn_layers = []\n",
    "        for layer in range(self.num_layers):\n",
    "            gcn_layers.append(ResidualGatedGCNLayer(self.hidden_dim, self.aggregation))\n",
    "        self.gcn_layers = nn.ModuleList(gcn_layers)\n",
    "        # Define MLP classifiers\n",
    "        self.mlp_edges = MLP(self.hidden_dim, self.voc_edges_out, self.mlp_layers)\n",
    "        # self.mlp_nodes = MLP(self.hidden_dim, self.voc_nodes_out, self.mlp_layers)\n",
    "\n",
    "    def forward(self, x_edges, x_edges_values, x_nodes, x_nodes_coord, y_edges=None, edge_cw=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x_edges: Input edge adjacency matrix (batch_size, num_nodes, num_nodes)\n",
    "            x_edges_values: Input edge distance matrix (batch_size, num_nodes, num_nodes)\n",
    "            x_nodes: Input nodes (batch_size, num_nodes)\n",
    "            x_nodes_coord: Input node coordinates (batch_size, num_nodes, node_dim)\n",
    "            y_edges: Targets for edges (batch_size, num_nodes, num_nodes)\n",
    "            edge_cw: Class weights for edges loss\n",
    "            # y_nodes: Targets for nodes (batch_size, num_nodes, num_nodes)\n",
    "            # node_cw: Class weights for nodes loss\n",
    "\n",
    "        Returns:\n",
    "            y_pred_edges: Predictions for edges (batch_size, num_nodes, num_nodes)\n",
    "            # y_pred_nodes: Predictions for nodes (batch_size, num_nodes)\n",
    "            loss: Value of loss function\n",
    "        \"\"\"\n",
    "        # Node and edge embedding\n",
    "        ## Todo: fix this but gives bugs for now\n",
    "        x_vals = self.nodes_coord_embedding(x_nodes_coord)  # B x V x H\n",
    "        x_tags = self.nodes_embedding(x_nodes)\n",
    "        x = torch.cat((x_vals, x_tags), -1)\n",
    "        # x = self.nodes_embedding2(x_nodes)\n",
    "        e_vals = self.edges_values_embedding(x_edges_values.unsqueeze(3))  # B x V x V x H\n",
    "        e_tags = self.edges_embedding(x_edges)  # B x V x V x H\n",
    "        e = torch.cat((e_vals, e_tags), -1)\n",
    "        #e = self.edges_values_embedding2(x_edges_values.unsqueeze(3))\n",
    "        # GCN layers\n",
    "        if self.num_segments_checkpoint != 0:\n",
    "            layer_functions = [lambda args: layer(*args) for layer in self.gcn_layers]\n",
    "            x, e = torch.utils.checkpoint.checkpoint_sequential(layer_functions, self.num_segments_checkpoint, (x, e))\n",
    "        else:\n",
    "            for layer in range(self.num_layers):\n",
    "                # B x V x H, B x V x V x H\n",
    "                x, e = self.gcn_layers[layer](x, e)\n",
    "        # MLP classifier\n",
    "        y_pred_edges = self.mlp_edges(e)  # B x V x V x voc_edges_out\n",
    "        # y_pred_nodes = self.mlp_nodes(x)  # B x V x voc_nodes_out\n",
    "\n",
    "        #loss = loss_edges(y_pred_edges, y_edges, edge_cw)\n",
    "        # Edge loss\n",
    "        y = F.log_softmax(y_pred_edges, dim=3)  # B x V x V x voc_edges\n",
    "        \n",
    "        y = torch.sigmoid(y)\n",
    "        y = torch.relu(y)\n",
    "        \n",
    "        # For some reason we must make things contiguous to prevent errors during backward\n",
    "        y_perm = y.permute(0, 3, 1, 2).contiguous()  # B x voc_edges x V x V\n",
    "        # y_perm = y.permute(0, 3, 1, 2).contiguous()\n",
    "        # if edge_cw == None:\n",
    "        #     edge_cw = [1 for i in range(101)]\n",
    "        # if type(edge_cw) != torch.Tensor:\n",
    "        #     edge_labels = y_edges.cpu().numpy().flatten()\n",
    "        #     edge_cw = compute_class_weight(\"balanced\", classes=np.unique(edge_labels), y=edge_labels).tolist()\n",
    "        # print(edge_cw)\n",
    "        if y_edges is not None:\n",
    "            # Compute loss\n",
    "            # print(\"forwarding1.1\")\n",
    "            if edge_cw != None:\n",
    "                edge_cw = torch.Tensor(edge_cw)  # Convert to tensors\n",
    "                # print(\"forwarding1.1.1\")\n",
    "                edge_cw = edge_cw.type(self.dtypeFloat)\n",
    "            # print(\"forwarding1.2\")\n",
    "                loss = nn.NLLLoss(edge_cw)\n",
    "            else:\n",
    "                loss = nn.NLLLoss()\n",
    "            # print(\"forwarding1.3\")\n",
    "            # print(y_perm)\n",
    "            # print(y_edges)\n",
    "            loss = loss(y_perm, y_edges)\n",
    "            # print(\"forwarding1.4\")\n",
    "        else:\n",
    "            # print(\"forwarding2.1\")\n",
    "            loss = None\n",
    "            # print(\"forwarding2.2\")\n",
    "        \n",
    "        # return y_pred_edges.permute(0, 3, 1, 2)[0]\n",
    "        return y, loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    if epoch == 51:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = 0.5 * param_group['lr']\n",
    "\n",
    "    loss_all = 0\n",
    "    for data in datatorch:\n",
    "        # data = data.to(device)\n",
    "        x_edges, x_edges_values, x_nodes, x_nodes_coord, _,  y_edges = data\n",
    "        optimizer.zero_grad()\n",
    "        # print(data.x, data.edge_index, data.batch)\n",
    "        output, loss = model(x_edges, x_edges_values, x_nodes, x_nodes_coord, y_edges)\n",
    "        # print(output, data.y)\n",
    "        # print(output)\n",
    "        # loss = F.l1_loss(output, y_edges)\n",
    "        loss.backward()\n",
    "        loss_all += loss.item()\n",
    "        optimizer.step()\n",
    "        test_size = 101*101*1 #extract batch size\n",
    "    return loss_all / test_size\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    test_size = 101*101*1 #extract batch size\n",
    "    for data in loader:\n",
    "        # data = data.to(device)\n",
    "        x_edges, x_edges_values, x_nodes, x_nodes_coord, _,  y_edges = data\n",
    "        output, _ = model(x_edges, x_edges_values, x_nodes, x_nodes_coord, y_edges)\n",
    "        pred = torch.tensor([[(1 if output[0][i][j][1] > output[0][i][j][0] else 0) for j in range(101)] for i in range(101)], dtype=torch.double)\n",
    "        correct += pred.eq(y_edges).sum().item()\n",
    "    return correct / test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: -0.0494, Train Acc: 1019.8394, Test Acc: 8.9319\n",
      "Epoch: 002, Loss: -0.0500, Train Acc: 1019.8394, Test Acc: 8.9319\n",
      "Epoch: 003, Loss: -0.0500, Train Acc: 1019.8394, Test Acc: 8.9319\n",
      "Epoch: 004, Loss: -0.0500, Train Acc: 1019.8394, Test Acc: 8.9319\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m11\u001b[39m):\n\u001b[0;32m      8\u001b[0m     loss \u001b[38;5;241m=\u001b[39m train(epoch)\n\u001b[1;32m----> 9\u001b[0m     train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatatorch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     test_acc \u001b[38;5;241m=\u001b[39m test(torchtest)\n\u001b[0;32m     11\u001b[0m     model_dict[epoch] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: deepcopy(model), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainAcc\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_acc, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtestAcc\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_acc}\n",
      "Cell \u001b[1;32mIn[13], line 33\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(loader)\u001b[0m\n\u001b[0;32m     31\u001b[0m     x_edges, x_edges_values, x_nodes, x_nodes_coord, _,  y_edges \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     32\u001b[0m     output, _ \u001b[38;5;241m=\u001b[39m model(x_edges, x_edges_values, x_nodes, x_nodes_coord, y_edges)\n\u001b[1;32m---> 33\u001b[0m     pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output[\u001b[38;5;241m0\u001b[39m][i][j][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m output[\u001b[38;5;241m0\u001b[39m][i][j][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m101\u001b[39m)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m101\u001b[39m)], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdouble)\n\u001b[0;32m     34\u001b[0m     correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pred\u001b[38;5;241m.\u001b[39meq(y_edges)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m correct \u001b[38;5;241m/\u001b[39m test_size\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model = ResidualGatedGCNModelVRP().to(device)\n",
    "model = ResidualGatedGCNModelVRP().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model_dict = {}\n",
    "\n",
    "for epoch in range(1, 11):\n",
    "    loss = train(epoch)\n",
    "    train_acc = test(datatorch)\n",
    "    test_acc = test(torchtest)\n",
    "    model_dict[epoch] = {\"model\": deepcopy(model), \"loss\": loss, \"trainAcc\": train_acc, \"testAcc\": test_acc}\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, '\n",
    "          f'Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('torch_convnet.pickle', 'wb') as handle:\n",
    "    pickle.dump(model_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('filename.pickle', 'rb') as handle:\n",
    "#     model_dict_restored = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "data_show = datatorch[0]\n",
    "x_edges, x_edges_values, x_nodes, x_nodes_coord, _,  y_edges = data_show\n",
    "output, _ = model(x_edges, x_edges_values, x_nodes, x_nodes_coord, y_edges)\n",
    "pred = torch.tensor([[(1 if exp(output[0][i][j][1])/(exp(output[0][i][j][1]) + exp(output[0][i][j][0])) > 0.9 and output[0][i][j][1] > 0 else 0) for j in range(101)] for i in range(101)], dtype=torch.double)\n",
    "y = y_edges[0]\n",
    "diff = 0\n",
    "for j in range(len(pred)):\n",
    "    a_list = [i.tolist() for i in pred[j]]\n",
    "    diff += sum([(y[j][i].tolist() - a_list[i])**2 for i in range(len(a_list))])\n",
    "    print([int(i) for i in pred[j]], sum(a_list))\n",
    "print(diff)\n",
    "print(sum([y[j][i].tolist() for i in range(101) for j in range(101)]))\n",
    "# for i in range(101):\n",
    "#     for j in range(101):\n",
    "#         print(output[0][i][j].tolist())\n",
    "edge_labels = y_edges.cpu().numpy().flatten()\n",
    "edge_cw = compute_class_weight(\"balanced\", classes=np.unique(edge_labels), y=edge_labels).tolist()\n",
    "# print(edge_cw)\n",
    "# print(y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
